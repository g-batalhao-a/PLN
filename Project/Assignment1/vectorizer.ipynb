{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test diferent Vectorizers and n-grams sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset = pd.read_excel('OpArticles_ADUs.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import RSLPStemmer\n",
    "\n",
    "corpus = []\n",
    "stemmer = RSLPStemmer()\n",
    "stopwords_list = stopwords.words('portuguese')\n",
    "stopwords_list.remove('n√£o')\n",
    "\n",
    "for i in range(0, dataset['tokens'].size):\n",
    "    review = re.sub('[^a-zA-Z\\u00C0-\\u00ff]', ' ', dataset['tokens'][i]).lower()\n",
    "    review = ' '.join([stemmer.stem(w) for w in review.split() if not w in set(stopwords_list)])\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document Representation\n",
    "\n",
    "We need to transform the data in the reduced-vocabulary corpus into a dataset that can be handled by machine learning models. Each review in our corpus is still rather unstructured: it is simply a lists of tokens. We will transform each review into a representation that makes use of the same set of features for the whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import time\n",
    "\n",
    "y = dataset['label']\n",
    "\n",
    "def test_vectorizer(vectorizer):\n",
    "    # Fit vectorizer\n",
    "    start = time.time()\n",
    "    X = vectorizer.fit_transform(corpus).toarray()\n",
    "    stop = time.time()\n",
    "    print(\"Vectorizer fit time: %0.2fs\" % (stop - start))\n",
    "    print(\"(Number of samples, Number of features):\", X.shape)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0, stratify=y)\n",
    "\n",
    "    # Classification\n",
    "    start = time.time()\n",
    "    clf = ComplementNB()\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    stop = time.time()\n",
    "\n",
    "    print(\"\\nModel time: %0.2fs\" % (stop - start))\n",
    "    print(\"\\nConfusion matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "    print(\"\\nClassification report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag-of-Words model\n",
    "\n",
    "The simplest way to do it is to create a *bag-of-words* model, which ignores word sequence.\n",
    "\n",
    "We can use scikit-learn's [CountVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html), which converts a collection of text documents to a matrix of token counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizer fit time: 0.42s\n",
      "(Number of samples, Number of features): (16743, 8256)\n",
      "\n",
      "Model time: 8.47s\n",
      "\n",
      "Confusion matrix:\n",
      " [[317  30 247  47  92]\n",
      " [  6  54  52   9  12]\n",
      " [291  63 861 143 263]\n",
      " [ 51  15  94  96  26]\n",
      " [ 81  21 161  23 294]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Fact       0.42      0.43      0.43       733\n",
      "      Policy       0.30      0.41      0.34       133\n",
      "       Value       0.61      0.53      0.57      1621\n",
      "    Value(+)       0.30      0.34      0.32       282\n",
      "    Value(-)       0.43      0.51      0.46       580\n",
      "\n",
      "    accuracy                           0.48      3349\n",
      "   macro avg       0.41      0.44      0.42      3349\n",
      "weighted avg       0.50      0.48      0.49      3349\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_vectorizer(CountVectorizer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-hot vectors\n",
    "\n",
    "[CountVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) includes a parameter (*binary*) that allows us to represent each review as a 1-hot vector with a 0 or a 1 for each of the features, indicating whether the corresponding token appears in the review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizer fit time: 0.31s\n",
      "(Number of samples, Number of features): (16743, 8256)\n",
      "\n",
      "Model time: 6.76s\n",
      "\n",
      "Confusion matrix:\n",
      " [[315  28 253  48  89]\n",
      " [  6  58  48  10  11]\n",
      " [302  67 863 133 256]\n",
      " [ 50  17  91  97  27]\n",
      " [ 76  21 162  22 299]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Fact       0.42      0.43      0.43       733\n",
      "      Policy       0.30      0.44      0.36       133\n",
      "       Value       0.61      0.53      0.57      1621\n",
      "    Value(+)       0.31      0.34      0.33       282\n",
      "    Value(-)       0.44      0.52      0.47       580\n",
      "\n",
      "    accuracy                           0.49      3349\n",
      "   macro avg       0.42      0.45      0.43      3349\n",
      "weighted avg       0.50      0.49      0.49      3349\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_vectorizer(CountVectorizer(binary=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF\n",
    "\n",
    "We can adjust the counts of each word in a document by considering how many times it occurs in the document (its *term frequency TF*) and in how many documents it occurs (its *document frequency DF*). [TfidfVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html) provides a way to directly obtain TF-IDF weighted features: the term frequency of a word is multiplied by its *inverse* document frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizer fit time: 0.32s\n",
      "(Number of samples, Number of features): (16743, 8256)\n",
      "\n",
      "Model time: 0.38s\n",
      "\n",
      "Confusion matrix:\n",
      " [[300  28 288  42  75]\n",
      " [  6  41  70   9   7]\n",
      " [263  66 968 112 212]\n",
      " [ 42  11 115  93  21]\n",
      " [ 69  28 196  18 269]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Fact       0.44      0.41      0.42       733\n",
      "      Policy       0.24      0.31      0.27       133\n",
      "       Value       0.59      0.60      0.59      1621\n",
      "    Value(+)       0.34      0.33      0.33       282\n",
      "    Value(-)       0.46      0.46      0.46       580\n",
      "\n",
      "    accuracy                           0.50      3349\n",
      "   macro avg       0.41      0.42      0.42      3349\n",
      "weighted avg       0.50      0.50      0.50      3349\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_vectorizer(TfidfVectorizer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TfidfVectorizer also contains _binary_ argument, where all non-zero term counts are set to 1. This does not mean outputs will have only 0/1 values, only that the tf term in tf-idf is binary. (Set idf and normalization to False to get 0/1 outputs).\n",
    "\n",
    "So we will only stick to the 3 representations above and procede testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizer fit time: 0.31s\n",
      "(Number of samples, Number of features): (16743, 8256)\n",
      "\n",
      "Model time: 0.40s\n",
      "\n",
      "Confusion matrix:\n",
      " [[ 307   19  306   38   63]\n",
      " [   9   33   77    8    6]\n",
      " [ 256   45 1045   95  180]\n",
      " [  37    9  126   87   23]\n",
      " [  70   23  209   21  257]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Fact       0.45      0.42      0.43       733\n",
      "      Policy       0.26      0.25      0.25       133\n",
      "       Value       0.59      0.64      0.62      1621\n",
      "    Value(+)       0.35      0.31      0.33       282\n",
      "    Value(-)       0.49      0.44      0.46       580\n",
      "\n",
      "    accuracy                           0.52      3349\n",
      "   macro avg       0.43      0.41      0.42      3349\n",
      "weighted avg       0.51      0.52      0.51      3349\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_vectorizer(TfidfVectorizer(binary=True, use_idf=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bi-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizer fit time: 0.52s\n",
      "(Number of samples, Number of features): (16743, 61558)\n",
      "\n",
      "Model time: 63.67s\n",
      "\n",
      "Confusion matrix:\n",
      " [[257 177 153  68  78]\n",
      " [  0  94  20  15   4]\n",
      " [289 424 584 131 193]\n",
      " [ 43  72  50 105  12]\n",
      " [ 63 141  98  17 261]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Fact       0.39      0.35      0.37       733\n",
      "      Policy       0.10      0.71      0.18       133\n",
      "       Value       0.65      0.36      0.46      1621\n",
      "    Value(+)       0.31      0.37      0.34       282\n",
      "    Value(-)       0.48      0.45      0.46       580\n",
      "\n",
      "    accuracy                           0.39      3349\n",
      "   macro avg       0.39      0.45      0.36      3349\n",
      "weighted avg       0.51      0.39      0.42      3349\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_vectorizer(CountVectorizer(ngram_range=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizer fit time: 0.64s\n",
      "(Number of samples, Number of features): (16743, 61558)\n",
      "\n",
      "Model time: 69.52s\n",
      "\n",
      "Confusion matrix:\n",
      " [[257 176 153  68  79]\n",
      " [  0  94  20  15   4]\n",
      " [289 424 583 132 193]\n",
      " [ 43  72  50 105  12]\n",
      " [ 63 141  98  17 261]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Fact       0.39      0.35      0.37       733\n",
      "      Policy       0.10      0.71      0.18       133\n",
      "       Value       0.64      0.36      0.46      1621\n",
      "    Value(+)       0.31      0.37      0.34       282\n",
      "    Value(-)       0.48      0.45      0.46       580\n",
      "\n",
      "    accuracy                           0.39      3349\n",
      "   macro avg       0.39      0.45      0.36      3349\n",
      "weighted avg       0.51      0.39      0.42      3349\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_vectorizer(CountVectorizer(binary=True, ngram_range=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizer fit time: 0.82s\n",
      "(Number of samples, Number of features): (16743, 61558)\n",
      "\n",
      "Model time: 5.28s\n",
      "\n",
      "Confusion matrix:\n",
      " [[263 173 157  63  77]\n",
      " [  0  93  22  15   3]\n",
      " [289 436 592 122 182]\n",
      " [ 41  75  53 105   8]\n",
      " [ 60 144 101  15 260]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Fact       0.40      0.36      0.38       733\n",
      "      Policy       0.10      0.70      0.18       133\n",
      "       Value       0.64      0.37      0.47      1621\n",
      "    Value(+)       0.33      0.37      0.35       282\n",
      "    Value(-)       0.49      0.45      0.47       580\n",
      "\n",
      "    accuracy                           0.39      3349\n",
      "   macro avg       0.39      0.45      0.37      3349\n",
      "weighted avg       0.51      0.39      0.43      3349\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_vectorizer(TfidfVectorizer(ngram_range=(2,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UniBi-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizer fit time: 1.21s\n",
      "(Number of samples, Number of features): (16743, 69814)\n",
      "\n",
      "Model time: 80.63s\n",
      "\n",
      "Confusion matrix:\n",
      " [[286  58 204  96  89]\n",
      " [  1  84  30  13   5]\n",
      " [303 158 736 182 242]\n",
      " [ 37  27  66 127  25]\n",
      " [ 67  49 121  36 307]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Fact       0.41      0.39      0.40       733\n",
      "      Policy       0.22      0.63      0.33       133\n",
      "       Value       0.64      0.45      0.53      1621\n",
      "    Value(+)       0.28      0.45      0.35       282\n",
      "    Value(-)       0.46      0.53      0.49       580\n",
      "\n",
      "    accuracy                           0.46      3349\n",
      "   macro avg       0.40      0.49      0.42      3349\n",
      "weighted avg       0.51      0.46      0.47      3349\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_vectorizer(CountVectorizer(ngram_range=(1,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizer fit time: 0.79s\n",
      "(Number of samples, Number of features): (16743, 69814)\n",
      "\n",
      "Model time: 80.70s\n",
      "\n",
      "Confusion matrix:\n",
      " [[283  61 201  96  92]\n",
      " [  1  85  29  13   5]\n",
      " [299 156 734 189 243]\n",
      " [ 37  28  64 129  24]\n",
      " [ 66  47 121  38 308]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Fact       0.41      0.39      0.40       733\n",
      "      Policy       0.23      0.64      0.33       133\n",
      "       Value       0.64      0.45      0.53      1621\n",
      "    Value(+)       0.28      0.46      0.35       282\n",
      "    Value(-)       0.46      0.53      0.49       580\n",
      "\n",
      "    accuracy                           0.46      3349\n",
      "   macro avg       0.40      0.49      0.42      3349\n",
      "weighted avg       0.51      0.46      0.47      3349\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_vectorizer(CountVectorizer(binary=True, ngram_range=(1,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizer fit time: 0.96s\n",
      "(Number of samples, Number of features): (16743, 69814)\n",
      "\n",
      "Model time: 8.49s\n",
      "\n",
      "Confusion matrix:\n",
      " [[ 292   26  287   55   73]\n",
      " [   3   63   54   10    3]\n",
      " [ 272   59 1003  101  186]\n",
      " [  36   14  101  110   21]\n",
      " [  64   21  196   14  285]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Fact       0.44      0.40      0.42       733\n",
      "      Policy       0.34      0.47      0.40       133\n",
      "       Value       0.61      0.62      0.61      1621\n",
      "    Value(+)       0.38      0.39      0.38       282\n",
      "    Value(-)       0.50      0.49      0.50       580\n",
      "\n",
      "    accuracy                           0.52      3349\n",
      "   macro avg       0.45      0.47      0.46      3349\n",
      "weighted avg       0.52      0.52      0.52      3349\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_vectorizer(TfidfVectorizer(ngram_range=(1,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "\n",
    "As we can see the _TfidfVectorizer_ achieve better results (not by much), and we think it is better to also take into account for the document frequency and not only the term count, so this is the Vectorizer that we will use for the classification tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore parameters\n",
    "\n",
    "In this section we will explore some of the parameters in order to achieve the best results possible while minimizing classification time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Strip accents\n",
    "\n",
    "Remove accents and perform other character normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizer fit time: 0.93s\n",
      "(Number of samples, Number of features): (16743, 69263)\n",
      "\n",
      "Model time: 5.44s\n",
      "\n",
      "Confusion matrix:\n",
      " [[ 287   25  297   50   74]\n",
      " [   3   62   55   10    3]\n",
      " [ 277   60 1003   94  187]\n",
      " [  36   14  103  110   19]\n",
      " [  62   20  198   16  284]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Fact       0.43      0.39      0.41       733\n",
      "      Policy       0.34      0.47      0.39       133\n",
      "       Value       0.61      0.62      0.61      1621\n",
      "    Value(+)       0.39      0.39      0.39       282\n",
      "    Value(-)       0.50      0.49      0.50       580\n",
      "\n",
      "    accuracy                           0.52      3349\n",
      "   macro avg       0.45      0.47      0.46      3349\n",
      "weighted avg       0.52      0.52      0.52      3349\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_vectorizer(TfidfVectorizer(ngram_range=(1,2), strip_accents='unicode'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though metrics are basically unchanged (in case of unigrams it lowers f1-score a lot), we are not sure how the words are affected turning into the same base form after the accents are stripped. Therefore we will not use this parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Document Frequency\n",
    "\n",
    "Ignore terms that appear less than 3 times, and terms that appear in more than 80% of the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizer fit time: 0.80s\n",
      "(Number of samples, Number of features): (16743, 19262)\n",
      "\n",
      "Model time: 1.33s\n",
      "\n",
      "Confusion matrix:\n",
      " [[301  16 307  40  69]\n",
      " [  4  58  58   8   5]\n",
      " [286  54 977  95 209]\n",
      " [ 39  13  96 115  19]\n",
      " [ 75  10 201  13 281]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Fact       0.43      0.41      0.42       733\n",
      "      Policy       0.38      0.44      0.41       133\n",
      "       Value       0.60      0.60      0.60      1621\n",
      "    Value(+)       0.42      0.41      0.42       282\n",
      "    Value(-)       0.48      0.48      0.48       580\n",
      "\n",
      "    accuracy                           0.52      3349\n",
      "   macro avg       0.46      0.47      0.47      3349\n",
      "weighted avg       0.52      0.52      0.52      3349\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_vectorizer(TfidfVectorizer(ngram_range=(1,2), min_df=3, max_df=0.8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same accuracy, higher f1-scores for the lower support classes, and significantly lower number of features. An important parameter to use in the classification task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UniBiTri-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizer fit time: 0.72s\n",
      "(Number of samples, Number of features): (16743, 30172)\n",
      "\n",
      "Model time: 1.51s\n",
      "\n",
      "Confusion matrix:\n",
      " [[ 278   22  335   34   64]\n",
      " [   5   49   66    9    4]\n",
      " [ 260   73 1028   74  186]\n",
      " [  38   13  109  105   17]\n",
      " [  61   13  243    7  256]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Fact       0.43      0.38      0.40       733\n",
      "      Policy       0.29      0.37      0.32       133\n",
      "       Value       0.58      0.63      0.60      1621\n",
      "    Value(+)       0.46      0.37      0.41       282\n",
      "    Value(-)       0.49      0.44      0.46       580\n",
      "\n",
      "    accuracy                           0.51      3349\n",
      "   macro avg       0.45      0.44      0.44      3349\n",
      "weighted avg       0.51      0.51      0.51      3349\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_vectorizer(TfidfVectorizer(ngram_range=(1,3), min_df=3, max_df=0.8))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "55f82424ee0038bf843e9f84700baa6bcc97076ded2739a9002049e8174a9129"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
