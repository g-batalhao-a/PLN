{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test diferent Vectorizers and n-grams sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset = pd.read_excel('OpArticles_ADUs.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleanup and normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fact não apen frut ignor', 'hav hum jorn investig preocup aprofund contextual histór isenç relat preocup soc urg denunci muit peç real jorn', 'tud cómic fif', 'tod permit organiz faç total absurd sent', 'não faz rir cust poder']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import RSLPStemmer\n",
    "\n",
    "corpus = []\n",
    "stemmer = RSLPStemmer()\n",
    "stopwords_list = stopwords.words('portuguese')\n",
    "# Remover algumas palavras da lista, p.ex. \"não\"\n",
    "stopwords_list.remove('não')\n",
    "\n",
    "for i in range(0, dataset['tokens'].size):\n",
    "    # get review, remove and lowercase non alpha chars\n",
    "    review = re.sub('[^a-zA-Z\\u00C0-\\u00ff]', ' ', dataset['tokens'][i]).lower()\n",
    "    # split into tokens, apply stemming and remove stop words\n",
    "    review = ' '.join([stemmer.stem(w) for w in review.split() if not w in set(stopwords_list)])\n",
    "    corpus.append(review)\n",
    "\n",
    "print(corpus[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating a data set\n",
    "\n",
    "We need to transform the data in the reduced-vocabulary corpus into a dataset that can be handled by machine learning models. Each review in our corpus is still rather unstructured: it is simply a lists of tokens. We will transform each review into a representation that makes use of the same set of features for the whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "import sklearn.metrics as metrics\n",
    "import time\n",
    "\n",
    "y = dataset['label']\n",
    "\n",
    "def test_vectorizer(vectorizer):\n",
    "    # Fit vectorizer\n",
    "    start = time.time()\n",
    "    X = vectorizer.fit_transform(corpus).toarray()\n",
    "    stop = time.time()\n",
    "    print(\"Vectorizer fit time: %0.2fs\" % (stop - start))\n",
    "    print(\"(Number of samples, Number of features):\", X.shape)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state=0, stratify=y, shuffle=True)\n",
    "\n",
    "    start = time.time()\n",
    "    clf = ComplementNB()\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    stop = time.time()\n",
    "\n",
    "    print(\"\\nModel time: %0.2fs\" % (stop - start))\n",
    "    print(\"\\nConfusion matrix:\\n\", metrics.confusion_matrix(y_test, y_pred))\n",
    "    print(\"\\nClassification report:\\n\", metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag-of-Words model\n",
    "\n",
    "The simplest way to do it is to create a *bag-of-words* model, which ignores word sequence.\n",
    "\n",
    "We can use scikit-learn's [CountVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html), which converts a collection of text documents to a matrix of token counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizer fit time: 0.39s\n",
      "(Number of samples, Number of features): (16743, 8256)\n",
      "\n",
      "Model time: 8.69s\n",
      "\n",
      "Confusion matrix:\n",
      " [[317  30 247  47  92]\n",
      " [  6  54  52   9  12]\n",
      " [291  63 861 143 263]\n",
      " [ 51  15  94  96  26]\n",
      " [ 81  21 161  23 294]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Fact       0.42      0.43      0.43       733\n",
      "      Policy       0.30      0.41      0.34       133\n",
      "       Value       0.61      0.53      0.57      1621\n",
      "    Value(+)       0.30      0.34      0.32       282\n",
      "    Value(-)       0.43      0.51      0.46       580\n",
      "\n",
      "    accuracy                           0.48      3349\n",
      "   macro avg       0.41      0.44      0.42      3349\n",
      "weighted avg       0.50      0.48      0.49      3349\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_vectorizer(CountVectorizer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-hot vectors\n",
    "\n",
    "[CountVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) includes a parameter (*binary*) that allows us to represent each review as a 1-hot vector with a 0 or a 1 for each of the features, indicating whether the corresponding token appears in the review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizer fit time: 0.30s\n",
      "(Number of samples, Number of features): (16743, 8256)\n",
      "\n",
      "Model time: 9.24s\n",
      "\n",
      "Confusion matrix:\n",
      " [[315  28 253  48  89]\n",
      " [  6  58  48  10  11]\n",
      " [302  67 863 133 256]\n",
      " [ 50  17  91  97  27]\n",
      " [ 76  21 162  22 299]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Fact       0.42      0.43      0.43       733\n",
      "      Policy       0.30      0.44      0.36       133\n",
      "       Value       0.61      0.53      0.57      1621\n",
      "    Value(+)       0.31      0.34      0.33       282\n",
      "    Value(-)       0.44      0.52      0.47       580\n",
      "\n",
      "    accuracy                           0.49      3349\n",
      "   macro avg       0.42      0.45      0.43      3349\n",
      "weighted avg       0.50      0.49      0.49      3349\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_vectorizer(CountVectorizer(binary=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF\n",
    "\n",
    "We can adjust the counts of each word in a document by considering how many times it occurs in the document (its *term frequency TF*) and in how many documents it occurs (its *document frequency DF*). [TfidfVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html) provides a way to directly obtain TF-IDF weighted features: the term frequency of a word is multiplied by its *inverse* document frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizer fit time: 0.37s\n",
      "(Number of samples, Number of features): (16743, 8256)\n",
      "\n",
      "Model time: 0.41s\n",
      "\n",
      "Confusion matrix:\n",
      " [[300  28 288  42  75]\n",
      " [  6  41  70   9   7]\n",
      " [263  66 968 112 212]\n",
      " [ 42  11 115  93  21]\n",
      " [ 69  28 196  18 269]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Fact       0.44      0.41      0.42       733\n",
      "      Policy       0.24      0.31      0.27       133\n",
      "       Value       0.59      0.60      0.59      1621\n",
      "    Value(+)       0.34      0.33      0.33       282\n",
      "    Value(-)       0.46      0.46      0.46       580\n",
      "\n",
      "    accuracy                           0.50      3349\n",
      "   macro avg       0.41      0.42      0.42      3349\n",
      "weighted avg       0.50      0.50      0.50      3349\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_vectorizer(TfidfVectorizer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bi-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizer fit time: 0.52s\n",
      "(Number of samples, Number of features): (16743, 61558)\n",
      "\n",
      "Model time: 67.52s\n",
      "\n",
      "Confusion matrix:\n",
      " [[257 177 153  68  78]\n",
      " [  0  94  20  15   4]\n",
      " [289 424 584 131 193]\n",
      " [ 43  72  50 105  12]\n",
      " [ 63 141  98  17 261]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Fact       0.39      0.35      0.37       733\n",
      "      Policy       0.10      0.71      0.18       133\n",
      "       Value       0.65      0.36      0.46      1621\n",
      "    Value(+)       0.31      0.37      0.34       282\n",
      "    Value(-)       0.48      0.45      0.46       580\n",
      "\n",
      "    accuracy                           0.39      3349\n",
      "   macro avg       0.39      0.45      0.36      3349\n",
      "weighted avg       0.51      0.39      0.42      3349\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_vectorizer(CountVectorizer(ngram_range=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizer fit time: 0.62s\n",
      "(Number of samples, Number of features): (16743, 61558)\n",
      "\n",
      "Model time: 59.72s\n",
      "\n",
      "Confusion matrix:\n",
      " [[257 176 153  68  79]\n",
      " [  0  94  20  15   4]\n",
      " [289 424 583 132 193]\n",
      " [ 43  72  50 105  12]\n",
      " [ 63 141  98  17 261]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Fact       0.39      0.35      0.37       733\n",
      "      Policy       0.10      0.71      0.18       133\n",
      "       Value       0.64      0.36      0.46      1621\n",
      "    Value(+)       0.31      0.37      0.34       282\n",
      "    Value(-)       0.48      0.45      0.46       580\n",
      "\n",
      "    accuracy                           0.39      3349\n",
      "   macro avg       0.39      0.45      0.36      3349\n",
      "weighted avg       0.51      0.39      0.42      3349\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_vectorizer(CountVectorizer(binary=True, ngram_range=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizer fit time: 0.56s\n",
      "(Number of samples, Number of features): (16743, 61558)\n",
      "\n",
      "Model time: 3.35s\n",
      "\n",
      "Confusion matrix:\n",
      " [[263 173 157  63  77]\n",
      " [  0  93  22  15   3]\n",
      " [289 436 592 122 182]\n",
      " [ 41  75  53 105   8]\n",
      " [ 60 144 101  15 260]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Fact       0.40      0.36      0.38       733\n",
      "      Policy       0.10      0.70      0.18       133\n",
      "       Value       0.64      0.37      0.47      1621\n",
      "    Value(+)       0.33      0.37      0.35       282\n",
      "    Value(-)       0.49      0.45      0.47       580\n",
      "\n",
      "    accuracy                           0.39      3349\n",
      "   macro avg       0.39      0.45      0.37      3349\n",
      "weighted avg       0.51      0.39      0.43      3349\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_vectorizer(TfidfVectorizer(ngram_range=(2,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UniBi-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizer fit time: 0.82s\n",
      "(Number of samples, Number of features): (16743, 69814)\n",
      "\n",
      "Model time: 70.65s\n",
      "\n",
      "Confusion matrix:\n",
      " [[286  58 204  96  89]\n",
      " [  1  84  30  13   5]\n",
      " [303 158 736 182 242]\n",
      " [ 37  27  66 127  25]\n",
      " [ 67  49 121  36 307]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Fact       0.41      0.39      0.40       733\n",
      "      Policy       0.22      0.63      0.33       133\n",
      "       Value       0.64      0.45      0.53      1621\n",
      "    Value(+)       0.28      0.45      0.35       282\n",
      "    Value(-)       0.46      0.53      0.49       580\n",
      "\n",
      "    accuracy                           0.46      3349\n",
      "   macro avg       0.40      0.49      0.42      3349\n",
      "weighted avg       0.51      0.46      0.47      3349\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_vectorizer(CountVectorizer(ngram_range=(1,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizer fit time: 0.66s\n",
      "(Number of samples, Number of features): (16743, 69814)\n",
      "\n",
      "Model time: 72.80s\n",
      "\n",
      "Confusion matrix:\n",
      " [[283  61 201  96  92]\n",
      " [  1  85  29  13   5]\n",
      " [299 156 734 189 243]\n",
      " [ 37  28  64 129  24]\n",
      " [ 66  47 121  38 308]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Fact       0.41      0.39      0.40       733\n",
      "      Policy       0.23      0.64      0.33       133\n",
      "       Value       0.64      0.45      0.53      1621\n",
      "    Value(+)       0.28      0.46      0.35       282\n",
      "    Value(-)       0.46      0.53      0.49       580\n",
      "\n",
      "    accuracy                           0.46      3349\n",
      "   macro avg       0.40      0.49      0.42      3349\n",
      "weighted avg       0.51      0.46      0.47      3349\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_vectorizer(CountVectorizer(binary=True, ngram_range=(1,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizer fit time: 0.63s\n",
      "(Number of samples, Number of features): (16743, 69814)\n",
      "\n",
      "Model time: 4.49s\n",
      "\n",
      "Confusion matrix:\n",
      " [[ 292   26  287   55   73]\n",
      " [   3   63   54   10    3]\n",
      " [ 272   59 1003  101  186]\n",
      " [  36   14  101  110   21]\n",
      " [  64   21  196   14  285]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Fact       0.44      0.40      0.42       733\n",
      "      Policy       0.34      0.47      0.40       133\n",
      "       Value       0.61      0.62      0.61      1621\n",
      "    Value(+)       0.38      0.39      0.38       282\n",
      "    Value(-)       0.50      0.49      0.50       580\n",
      "\n",
      "    accuracy                           0.52      3349\n",
      "   macro avg       0.45      0.47      0.46      3349\n",
      "weighted avg       0.52      0.52      0.52      3349\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_vectorizer(TfidfVectorizer(ngram_range=(1,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Skip accents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizer fit time: 0.30s\n",
      "(Number of samples, Number of features): (16743, 8256)\n",
      "\n",
      "Model time: 0.37s\n",
      "\n",
      "Confusion matrix:\n",
      " [[300  28 288  42  75]\n",
      " [  6  41  70   9   7]\n",
      " [263  66 968 112 212]\n",
      " [ 42  11 115  93  21]\n",
      " [ 69  28 196  18 269]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Fact       0.44      0.41      0.42       733\n",
      "      Policy       0.24      0.31      0.27       133\n",
      "       Value       0.59      0.60      0.59      1621\n",
      "    Value(+)       0.34      0.33      0.33       282\n",
      "    Value(-)       0.46      0.46      0.46       580\n",
      "\n",
      "    accuracy                           0.50      3349\n",
      "   macro avg       0.41      0.42      0.42      3349\n",
      "weighted avg       0.50      0.50      0.50      3349\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vect = TfidfVectorizer()\n",
    "vect.fit_transform(corpus).toarray()\n",
    "test_vectorizer(vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizer fit time: 0.40s\n",
      "(Number of samples, Number of features): (16743, 7843)\n",
      "\n",
      "Model time: 0.35s\n",
      "\n",
      "Confusion matrix:\n",
      " [[298  23 292  46  74]\n",
      " [  8  38  70  10   7]\n",
      " [270  65 954 112 220]\n",
      " [ 38  12 117  95  20]\n",
      " [ 69  29 190  20 272]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Fact       0.44      0.41      0.42       733\n",
      "      Policy       0.23      0.29      0.25       133\n",
      "       Value       0.59      0.59      0.59      1621\n",
      "    Value(+)       0.34      0.34      0.34       282\n",
      "    Value(-)       0.46      0.47      0.46       580\n",
      "\n",
      "    accuracy                           0.49      3349\n",
      "   macro avg       0.41      0.42      0.41      3349\n",
      "weighted avg       0.50      0.49      0.50      3349\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vect = TfidfVectorizer(strip_accents='unicode')\n",
    "vect.fit_transform(corpus).toarray()\n",
    "test_vectorizer(vect)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "55f82424ee0038bf843e9f84700baa6bcc97076ded2739a9002049e8174a9129"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
