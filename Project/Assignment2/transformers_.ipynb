{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkryzQyiugjy"
      },
      "source": [
        "Notebook prepared by Henrique Lopes Cardoso (hlc@fe.up.pt).\n",
        "\n",
        "# TRANSFORMERS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8q3PPnaT4D4"
      },
      "source": [
        "In this notebook we will explore [Hugging Face Transformers](https://huggingface.co/docs/transformers/index).\n",
        "You may also want to check the [Hugging Face course](https://huggingface.co/course/), which will explain you how to use this technology in a much greater depth.\n",
        "\n",
        "Training transformer models is computationally expensive. Hugging Face makes available several pretrained [models](https://huggingface.co/models) that can be used as is, or fine-tuned to a specific NLP task, such as one of sentence classification. That's what we'll do in this notebook.\n",
        "\n",
        "Hugging Face also makes available several [datasets](https://huggingface.co/datasets) that can be used to train or fine-tune a model.\n",
        "\n",
        "See:\n",
        "- https://huggingface.co/docs/transformers/tasks/sequence_classification#preprocess\n",
        "- https://huggingface.co/docs/transformers/training#prepare-a-dataset\n",
        "- https://huggingface.co/docs/transformers/accelerate\n",
        "- https://huggingface.co/docs/transformers/model_summary#autoencoding-models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6yUirr1T4D5"
      },
      "source": [
        "## Loading a dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "boTA3XenT4D5"
      },
      "source": [
        "In this notebook, we'll start by using a local dataset (instead of using a dataset stored at Hugging Face).\n",
        "Let's load data for our classification task."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas\n",
        "!pip install datasets\n",
        "!pip install transformers\n",
        "!pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113"
      ],
      "metadata": {
        "id": "DqvXISYRVQ6p",
        "outputId": "72ff57e3-cdec-4e3f-fd24-692c32ab6fde",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.3.5)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2022.1)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.21.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (2.2.2)\n",
            "Requirement already satisfied: dill<0.3.5 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.6)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.11.4)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.18.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.64.0)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.7.0)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2022.5.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.7.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.2.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2022.5.18.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.25.11)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.2.0)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.7.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.4.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.8.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.19.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.5.18.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.25.11)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/, https://download.pytorch.org/whl/cu113\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.11.0+cu113)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.12.0+cu113)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.7/dist-packages (0.11.0+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (4.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision) (2.23.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.21.6)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (1.25.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (2022.5.18.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "EwL0UYu3T4D6",
        "outputId": "cf65d847-a6e1-43b9-f45c-6fa51526fe8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              tokens  label\n",
              "0           O facto não é apenas fruto da ignorância      0\n",
              "1  havia no seu humor mais jornalismo (mais inves...      0\n",
              "2                              É tudo cómico na FIFA      0\n",
              "3  o que todos nós permitimos que esta organizaçã...      0\n",
              "4            não nos fazem rir à custa dos poderosos      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e46767bc-4520-4dac-a5d3-7b0bbf6fe2dc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tokens</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>O facto não é apenas fruto da ignorância</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>havia no seu humor mais jornalismo (mais inves...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>É tudo cómico na FIFA</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>o que todos nós permitimos que esta organizaçã...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>não nos fazem rir à custa dos poderosos</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e46767bc-4520-4dac-a5d3-7b0bbf6fe2dc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e46767bc-4520-4dac-a5d3-7b0bbf6fe2dc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e46767bc-4520-4dac-a5d3-7b0bbf6fe2dc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Importing the dataset\n",
        "dataset = pd.read_excel(\"./data/OpArticles_ADUs.xlsx\")\n",
        "dataset = dataset.drop(columns=['article_id', 'annotator', 'node','ranges'])\n",
        "dataset['label'].replace(['Value', 'Value(+)', 'Value(-)', 'Fact', 'Policy'],[0,1,2,3,4], inplace=True)\n",
        "\n",
        "dataset.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UX0JQf3zT4D7"
      },
      "source": [
        "For ease of usage with Transformer models, we convert the dataset into a Hugging Face dataset and split it into train, validation and test sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ltHZiXtiT4D8"
      },
      "outputs": [],
      "source": [
        "from datasets import Dataset\n",
        "\n",
        "dataset_hf = Dataset.from_pandas(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "SBuO31lRT4D8"
      },
      "outputs": [],
      "source": [
        "from datasets import DatasetDict\n",
        "\n",
        "# 90% train, 10% test+validation\n",
        "train_test = dataset_hf.train_test_split(test_size=0.1)\n",
        "\n",
        "# Split the 10% test+validation set in half test, half validation\n",
        "valid_test = train_test['test'].train_test_split(test_size=0.5)\n",
        "\n",
        "# gather everyone if you want to have a single DatasetDict\n",
        "train_valid_test_dataset = DatasetDict({\n",
        "    'train': train_test['train'],\n",
        "    'validation': valid_test['train'],\n",
        "    'test': valid_test['test']\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "WcOHKbJZT4D9",
        "outputId": "ef77a62c-b7fe-4c6d-c5e6-c97c6bf67f8b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['tokens', 'label'],\n",
              "        num_rows: 15068\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['tokens', 'label'],\n",
              "        num_rows: 837\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['tokens', 'label'],\n",
              "        num_rows: 838\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "train_valid_test_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zyUwAwWaT4D-"
      },
      "source": [
        "## Fine-tuning a pretrained model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hO9TWPcoT4D-"
      },
      "source": [
        "As a starting example, we'll use a lighter BERT-based model. We will need to load:\n",
        "- the [tokenizer](https://huggingface.co/docs/transformers/autoclass_tutorial#autotokenizer) (which is used to [preprocess](https://huggingface.co/docs/transformers/preprocessing) the data before it can be used by the model)\n",
        "- the [model](https://huggingface.co/docs/transformers/autoclass_tutorial#automodel) itself"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "8Vmc1NztT4D_"
      },
      "outputs": [],
      "source": [
        "model_name = \"neuralmind/bert-base-portuguese-cased\" # or neuralmind/bert-large-portuguese-cased"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zA2HzqzVT4EB"
      },
      "source": [
        "### Tokenizer\n",
        "\n",
        "We first load the tokenizer for our model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "scrolled": true,
        "id": "4KTZJol_T4EB"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "def get_tokenizer(name):\n",
        "    return AutoTokenizer.from_pretrained(name, model_max_len=512)\n",
        "\n",
        "tokenizer = get_tokenizer(model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwU7Axm2T4EC"
      },
      "source": [
        "Now we need to [preprocess](https://huggingface.co/docs/transformers/preprocessing) our data. We will do it for the three partitions (train, validation and test) in a single step. For that, we'll make use of [map](https://huggingface.co/docs/datasets/process#map) with the help of an auxiliary function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "GsP9D67FT4EC"
      },
      "outputs": [],
      "source": [
        "def preprocess_function(sample):\n",
        "    return tokenizer(sample[\"tokens\"], truncation=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "dbtKsaV8T4ED",
        "outputId": "efa6ebe2-1587-42d1-992b-0da0ab1ab2e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 150,
          "referenced_widgets": [
            "36d4526adc5d47629ba603c5df46b243",
            "b306cfe93ab44128840561f1345c9016",
            "0636bdff4a2043b4b954ee136bf86344",
            "ecc0d68b548c4fe692e4d8d4e5bf807d",
            "dbdb2753385042dbab50025456048ce2",
            "ff67fc6cfb494896800482187befc142",
            "31c4d4af07de446994419cdba2c1113d",
            "71d36b9847d54970a1a859d4ed2e883f",
            "3f3e695ec5594eb5bd87ca603b4fc6cb",
            "9de20244084748f0be6277d17616e84c",
            "a9a1d407a693407dabbe27ea6bda367e",
            "96c812663c494400bcc34da831f50e78",
            "3b051ac83599451ca7ebab4e4c7ba1cd",
            "577af2d225f24d0f9bf5aada5cf6c853",
            "c31d7ca0c82244b2a5addfdb6326c461",
            "3baafd0d5d7641a7b089093400edae42",
            "72ffbd33630a4378a65cb469ab5794b4",
            "5d8ea16e81b64f8c95dc4ce4e314a936",
            "3e44e7ac28604b2fbc07528211da887d",
            "fff7eec9c01f4a23867fe3b9e95bac72",
            "a75fa04969884cbb9a0c3f8594c29d93",
            "ac8e7e9a61254c34973e204098f2c59a",
            "1391a8b8214e4dfd9847edbb6cb6f94e",
            "246560a14b4e4ee9a2bfbe13c68c44fa",
            "9330bbbb325f431c80a9386d22a3415f",
            "f1d084b7da674a9aabfb933f57c88176",
            "42b2c21c8a754733bc370e4e3ec7b4b2",
            "fda6f3526ff0484cb76463e2d57f9a8e",
            "600f7ec6343f4be18cd5b94cfc4581d5",
            "5abc87d016694764ad630d0afce5341d",
            "a6c64e87df524376a89a964a0a5e6aee",
            "400b7a93278349788eae044f406d4fac",
            "0d5e48a7c6da424ba29ae2d81db3682a"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/16 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "36d4526adc5d47629ba603c5df46b243"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "96c812663c494400bcc34da831f50e78"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1391a8b8214e4dfd9847edbb6cb6f94e"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "def get_tokenized_data(dataset, function):\n",
        "    return dataset.map(function, batched=True)\n",
        "\n",
        "tokenized_dataset = get_tokenized_data(train_valid_test_dataset,preprocess_function)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "tmt-s6v3T4ED",
        "outputId": "a05fdd53-97c0-42f7-86fe-72435b559c22",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['tokens', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
              "        num_rows: 15068\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['tokens', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
              "        num_rows: 837\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['tokens', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
              "        num_rows: 838\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "tokenized_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iov7UbfXT4ED"
      },
      "source": [
        "When preprocessing the text, we have actually translated the text into numbers, which is known as [encoding](https://huggingface.co/course/chapter2/4?fw=pt#encoding)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "KsrDrbF9T4ED",
        "outputId": "66a6e8db-c3fd-429a-decf-3a6c10d4069f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'attention_mask': [1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1],\n",
              " 'input_ids': [101,\n",
              "  785,\n",
              "  1695,\n",
              "  744,\n",
              "  262,\n",
              "  7302,\n",
              "  173,\n",
              "  3401,\n",
              "  125,\n",
              "  12883,\n",
              "  179,\n",
              "  6028,\n",
              "  22303,\n",
              "  123,\n",
              "  333,\n",
              "  15893,\n",
              "  285,\n",
              "  1839,\n",
              "  366,\n",
              "  5080,\n",
              "  298,\n",
              "  10069,\n",
              "  19849,\n",
              "  358,\n",
              "  125,\n",
              "  10325,\n",
              "  6861,\n",
              "  102],\n",
              " 'label': 3,\n",
              " 'token_type_ids': [0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0],\n",
              " 'tokens': 'muito pouco ainda foi definido em termos de exportação que continuará a ser permitida dentro das regras dos mercados adquirentes de talentos britânicos'}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "tokenized_dataset['train'][321]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZdByQQqIT4EE"
      },
      "source": [
        "Encoding is done in a two-step process: tokenization, followed by conversion to input IDs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "OJU6dPkhT4EE",
        "outputId": "131e384a-4e63-428d-af9c-72670c8c6c3a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['muito', 'pouco', 'ainda', 'foi', 'definido', 'em', 'termos', 'de', 'exportação', 'que', 'continuar', '##á', 'a', 'ser', 'permiti', '##da', 'dentro', 'das', 'regras', 'dos', 'mercados', 'adquire', '##ntes', 'de', 'talentos', 'britânicos']\n",
            "[785, 1695, 744, 262, 7302, 173, 3401, 125, 12883, 179, 6028, 22303, 123, 333, 15893, 285, 1839, 366, 5080, 298, 10069, 19849, 358, 125, 10325, 6861]\n"
          ]
        }
      ],
      "source": [
        "tokens = tokenizer.tokenize(tokenized_dataset['train'][321]['tokens'])\n",
        "print(tokens)\n",
        "ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "print(ids)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65Odbx0ZT4EE"
      },
      "source": [
        "The tokenizer actually adds two special tokens when preprocessing: one at the beginning, and one at the end."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "0nXLegtuT4EE",
        "outputId": "ca8fe2f9-0173-44c0-8e8f-a4a5a4211745",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[101,\n",
              " 785,\n",
              " 1695,\n",
              " 744,\n",
              " 262,\n",
              " 7302,\n",
              " 173,\n",
              " 3401,\n",
              " 125,\n",
              " 12883,\n",
              " 179,\n",
              " 6028,\n",
              " 22303,\n",
              " 123,\n",
              " 333,\n",
              " 15893,\n",
              " 285,\n",
              " 1839,\n",
              " 366,\n",
              " 5080,\n",
              " 298,\n",
              " 10069,\n",
              " 19849,\n",
              " 358,\n",
              " 125,\n",
              " 10325,\n",
              " 6861,\n",
              " 102]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "inputs = tokenizer(tokenized_dataset['train'][321]['tokens'])\n",
        "inputs['input_ids']   # or inputs.input_ids"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWj6CtzGT4EF"
      },
      "source": [
        "We can [decode](https://huggingface.co/course/chapter2/4?fw=pt#decoding) the sequence to check what are these tokens:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "f5nLE0_tT4EF",
        "outputId": "f33fc867-400c-4529-df3a-591931260a40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'[CLS] muito pouco ainda foi definido em termos de exportação que continuará a ser permitida dentro das regras dos mercados adquirentes de talentos britânicos [SEP]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "tokenizer.decode(inputs['input_ids'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5pHgySuoT4EF"
      },
      "source": [
        "As with enconding, we can decode in two separate steps:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "i7OOkxf3T4EF",
        "outputId": "5406d19c-b0d6-4cbe-8b97-451f2f572c5c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['[CLS]', 'muito', 'pouco', 'ainda', 'foi', 'definido', 'em', 'termos', 'de', 'exportação', 'que', 'continuar', '##á', 'a', 'ser', 'permiti', '##da', 'dentro', 'das', 'regras', 'dos', 'mercados', 'adquire', '##ntes', 'de', 'talentos', 'britânicos', '[SEP]']\n",
            "[CLS] muito pouco ainda foi definido em termos de exportação que continuará a ser permitida dentro das regras dos mercados adquirentes de talentos britânicos [SEP]\n"
          ]
        }
      ],
      "source": [
        "tokens = tokenizer.convert_ids_to_tokens(inputs['input_ids'])\n",
        "print(tokens)\n",
        "print(tokenizer.convert_tokens_to_string(tokens))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVhiKvsET4EG"
      },
      "source": [
        "### Loading the model\n",
        "\n",
        "We now load the pretrained model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "jWdXIPrwT4EG",
        "outputId": "a1cf0356-37fb-4f76-9bd6-5ee8b81f035d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at neuralmind/bert-base-portuguese-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertModel(\n",
              "  (embeddings): BertEmbeddings(\n",
              "    (word_embeddings): Embedding(29794, 768, padding_idx=0)\n",
              "    (position_embeddings): Embedding(512, 768)\n",
              "    (token_type_embeddings): Embedding(2, 768)\n",
              "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): BertEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (2): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (3): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (4): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (5): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (6): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (7): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (8): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (9): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (10): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (11): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): BertPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "from transformers import AutoModel\n",
        "\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "model.cuda()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCzyr5DrT4EG"
      },
      "source": [
        "Loading the model in this way only gets us the base Transformer module: given some inputs, we obtain the hidden state of the model -- a high-dimensional vector representing the \"contextual understanding\" of that input by the Transformer model.\n",
        "\n",
        "In other words, we are leaving out the *head* of the model, which is needed for whatever NLP task we want to address."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SptaytWjT4EG"
      },
      "source": [
        "Since we want to use the model for classification, we should load it with an appropriate classification head:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "aTRvqR7TT4EH",
        "outputId": "ffac29e5-6d37-408a-f2ec-8c92fcd3697b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at neuralmind/bert-base-portuguese-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at neuralmind/bert-base-portuguese-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(29794, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "import torch\n",
        "\n",
        "def get_model(name):\n",
        "    return AutoModelForSequenceClassification.from_pretrained(name, num_labels=5)\n",
        "\n",
        "model = get_model(model_name)\n",
        "model.cuda()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KG5h2J_FT4EI"
      },
      "source": [
        "### Fine-tuning\n",
        "\n",
        "The next step is to [fine-tune](https://huggingface.co/docs/transformers/training) the model with our train data. To do so, we can make use of a [Trainer](https://huggingface.co/docs/transformers/main_classes/trainer).\n",
        "There are several aspects of training that you can specify via [TrainingArguments](https://huggingface.co/docs/transformers/main_classes/trainer#transformers.TrainingArguments)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "JKPJ6Jr2T4EI"
      },
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "from transformers import DataCollatorWithPadding\n",
        "from datasets import load_metric\n",
        "import numpy as np\n",
        "\n",
        "metric = load_metric(\"accuracy\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    return metric.compute(predictions=predictions, references=labels)\n",
        "\n",
        "def get_trainingArgs():\n",
        "    return TrainingArguments(\n",
        "        output_dir=\"./results\",\n",
        "        learning_rate=2e-5,\n",
        "        per_device_train_batch_size=16,\n",
        "        per_device_eval_batch_size=16,\n",
        "        num_train_epochs=10,\n",
        "        weight_decay=0.01,\n",
        "        evaluation_strategy=\"epoch\", # run validation at the end of each epoch\n",
        "        save_strategy=\"epoch\",\n",
        "        load_best_model_at_end=True,\n",
        "    )\n",
        "\n",
        "training_args = get_trainingArgs()\n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "def get_trainer(model_, args_, dataset_, tokenizer_, data_collator_, compute_metrics_):\n",
        "    return Trainer(\n",
        "        model=model_,\n",
        "        args=args_,\n",
        "        train_dataset=dataset_[\"train\"],\n",
        "        eval_dataset=dataset_[\"validation\"],\n",
        "        tokenizer=tokenizer_,\n",
        "        data_collator=data_collator_,\n",
        "        compute_metrics=compute_metrics_\n",
        "    )\n",
        "\n",
        "trainer = get_trainer(model,training_args,tokenized_dataset,tokenizer,data_collator,compute_metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "lJgizsL2T4EJ",
        "outputId": "29c8c467-ed92-4ef2-e38a-5cb21e327b84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: tokens. If tokens are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 15068\n",
            "  Num Epochs = 10\n",
            "  Instantaneous batch size per device = 16\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 9420\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='9420' max='9420' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [9420/9420 27:34, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.110300</td>\n",
              "      <td>0.911923</td>\n",
              "      <td>0.606930</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.786300</td>\n",
              "      <td>0.925328</td>\n",
              "      <td>0.609319</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.620200</td>\n",
              "      <td>1.034465</td>\n",
              "      <td>0.593787</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.511900</td>\n",
              "      <td>1.179615</td>\n",
              "      <td>0.574671</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.440600</td>\n",
              "      <td>1.278867</td>\n",
              "      <td>0.584229</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.388800</td>\n",
              "      <td>1.483417</td>\n",
              "      <td>0.583035</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.345400</td>\n",
              "      <td>1.597407</td>\n",
              "      <td>0.565114</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.311300</td>\n",
              "      <td>1.651575</td>\n",
              "      <td>0.574671</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.269300</td>\n",
              "      <td>1.821028</td>\n",
              "      <td>0.573477</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.240600</td>\n",
              "      <td>1.883662</td>\n",
              "      <td>0.567503</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: tokens. If tokens are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 837\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to ./results/checkpoint-942\n",
            "Configuration saved in ./results/checkpoint-942/config.json\n",
            "Model weights saved in ./results/checkpoint-942/pytorch_model.bin\n",
            "tokenizer config file saved in ./results/checkpoint-942/tokenizer_config.json\n",
            "Special tokens file saved in ./results/checkpoint-942/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: tokens. If tokens are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 837\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to ./results/checkpoint-1884\n",
            "Configuration saved in ./results/checkpoint-1884/config.json\n",
            "Model weights saved in ./results/checkpoint-1884/pytorch_model.bin\n",
            "tokenizer config file saved in ./results/checkpoint-1884/tokenizer_config.json\n",
            "Special tokens file saved in ./results/checkpoint-1884/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: tokens. If tokens are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 837\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to ./results/checkpoint-2826\n",
            "Configuration saved in ./results/checkpoint-2826/config.json\n",
            "Model weights saved in ./results/checkpoint-2826/pytorch_model.bin\n",
            "tokenizer config file saved in ./results/checkpoint-2826/tokenizer_config.json\n",
            "Special tokens file saved in ./results/checkpoint-2826/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: tokens. If tokens are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 837\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to ./results/checkpoint-3768\n",
            "Configuration saved in ./results/checkpoint-3768/config.json\n",
            "Model weights saved in ./results/checkpoint-3768/pytorch_model.bin\n",
            "tokenizer config file saved in ./results/checkpoint-3768/tokenizer_config.json\n",
            "Special tokens file saved in ./results/checkpoint-3768/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: tokens. If tokens are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 837\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to ./results/checkpoint-4710\n",
            "Configuration saved in ./results/checkpoint-4710/config.json\n",
            "Model weights saved in ./results/checkpoint-4710/pytorch_model.bin\n",
            "tokenizer config file saved in ./results/checkpoint-4710/tokenizer_config.json\n",
            "Special tokens file saved in ./results/checkpoint-4710/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: tokens. If tokens are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 837\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to ./results/checkpoint-5652\n",
            "Configuration saved in ./results/checkpoint-5652/config.json\n",
            "Model weights saved in ./results/checkpoint-5652/pytorch_model.bin\n",
            "tokenizer config file saved in ./results/checkpoint-5652/tokenizer_config.json\n",
            "Special tokens file saved in ./results/checkpoint-5652/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: tokens. If tokens are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 837\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to ./results/checkpoint-6594\n",
            "Configuration saved in ./results/checkpoint-6594/config.json\n",
            "Model weights saved in ./results/checkpoint-6594/pytorch_model.bin\n",
            "tokenizer config file saved in ./results/checkpoint-6594/tokenizer_config.json\n",
            "Special tokens file saved in ./results/checkpoint-6594/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: tokens. If tokens are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 837\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to ./results/checkpoint-7536\n",
            "Configuration saved in ./results/checkpoint-7536/config.json\n",
            "Model weights saved in ./results/checkpoint-7536/pytorch_model.bin\n",
            "tokenizer config file saved in ./results/checkpoint-7536/tokenizer_config.json\n",
            "Special tokens file saved in ./results/checkpoint-7536/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: tokens. If tokens are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 837\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to ./results/checkpoint-8478\n",
            "Configuration saved in ./results/checkpoint-8478/config.json\n",
            "Model weights saved in ./results/checkpoint-8478/pytorch_model.bin\n",
            "tokenizer config file saved in ./results/checkpoint-8478/tokenizer_config.json\n",
            "Special tokens file saved in ./results/checkpoint-8478/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: tokens. If tokens are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 837\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to ./results/checkpoint-9420\n",
            "Configuration saved in ./results/checkpoint-9420/config.json\n",
            "Model weights saved in ./results/checkpoint-9420/pytorch_model.bin\n",
            "tokenizer config file saved in ./results/checkpoint-9420/tokenizer_config.json\n",
            "Special tokens file saved in ./results/checkpoint-9420/special_tokens_map.json\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from ./results/checkpoint-942 (score: 0.9119234085083008).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=9420, training_loss=0.4949805897512254, metrics={'train_runtime': 1654.402, 'train_samples_per_second': 91.078, 'train_steps_per_second': 5.694, 'total_flos': 3807465469798728.0, 'train_loss': 0.4949805897512254, 'epoch': 10.0})"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BaFpoDmqT4EJ"
      },
      "source": [
        "We can check the model's performance in the evaluation set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "OMWYLKcTT4EJ",
        "outputId": "1a7bd318-94ab-4e9a-aa1a-9f0dc135589c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: tokens. If tokens are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 837\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='53' max='53' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [53/53 00:02]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'epoch': 10.0,\n",
              " 'eval_accuracy': 0.6069295101553166,\n",
              " 'eval_loss': 0.9119234085083008,\n",
              " 'eval_runtime': 2.7416,\n",
              " 'eval_samples_per_second': 305.294,\n",
              " 'eval_steps_per_second': 19.332}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "trainer.evaluate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h5vbAVbmT4EJ"
      },
      "source": [
        "And more importantly, we can check how the model fares in our test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "cmCY5qmsT4EJ",
        "outputId": "c5d3b624-da90-4039-f40e-9b6ff4088060",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 925
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the test set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: tokens. If tokens are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Prediction *****\n",
            "  Num examples = 838\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='106' max='53' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [53/53 00:05]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PredictionOutput(predictions=array([[ 0.3760135 , -1.5194662 ,  2.8067956 ,  0.48898378, -1.9309182 ],\n",
              "       [ 1.3340023 ,  2.0924182 , -1.9254823 , -0.24892047, -1.7757592 ],\n",
              "       [ 0.65512687, -0.85574234, -0.71937895,  3.2252967 , -2.5290272 ],\n",
              "       ...,\n",
              "       [ 2.8552709 , -1.5310497 ,  0.7302812 ,  1.508096  , -2.8344948 ],\n",
              "       [ 1.3395143 , -0.9876522 , -1.1002288 , -1.0114254 ,  2.6395814 ],\n",
              "       [ 0.7530727 , -1.8906747 ,  3.2568834 ,  0.32288778, -2.2073815 ]],\n",
              "      dtype=float32), label_ids=array([2, 1, 2, 3, 0, 1, 3, 0, 0, 0, 0, 0, 3, 0, 0, 3, 0, 0, 0, 0, 1, 2,\n",
              "       0, 3, 0, 0, 0, 2, 2, 0, 3, 3, 0, 2, 2, 0, 0, 2, 0, 0, 2, 2, 2, 3,\n",
              "       0, 3, 0, 0, 2, 0, 0, 1, 3, 0, 2, 0, 3, 3, 3, 0, 3, 0, 0, 1, 2, 2,\n",
              "       3, 2, 0, 0, 3, 0, 2, 3, 0, 0, 0, 3, 3, 0, 0, 0, 0, 2, 0, 4, 0, 0,\n",
              "       0, 3, 0, 3, 0, 0, 0, 0, 3, 0, 3, 0, 3, 4, 0, 0, 0, 0, 0, 2, 3, 0,\n",
              "       0, 0, 0, 0, 0, 2, 3, 0, 0, 3, 2, 0, 3, 4, 2, 3, 0, 0, 0, 0, 2, 0,\n",
              "       0, 0, 3, 3, 0, 2, 3, 0, 0, 2, 0, 1, 0, 0, 3, 0, 2, 0, 3, 2, 0, 2,\n",
              "       0, 3, 0, 3, 2, 3, 3, 0, 0, 1, 1, 3, 3, 0, 0, 3, 0, 2, 3, 3, 3, 0,\n",
              "       2, 0, 0, 3, 0, 0, 0, 3, 2, 0, 2, 3, 3, 2, 4, 0, 3, 2, 1, 1, 2, 1,\n",
              "       2, 0, 2, 2, 0, 3, 0, 3, 0, 0, 2, 2, 2, 0, 0, 4, 0, 3, 0, 1, 2, 0,\n",
              "       3, 3, 2, 2, 2, 3, 0, 0, 1, 3, 0, 3, 1, 4, 0, 0, 0, 0, 3, 0, 3, 2,\n",
              "       1, 2, 0, 4, 3, 0, 0, 4, 0, 1, 0, 3, 0, 3, 1, 3, 0, 0, 0, 0, 3, 2,\n",
              "       0, 0, 0, 4, 0, 0, 0, 0, 0, 3, 4, 3, 0, 2, 3, 2, 0, 3, 2, 4, 3, 2,\n",
              "       0, 4, 0, 2, 2, 0, 3, 0, 0, 3, 0, 4, 0, 1, 0, 2, 3, 0, 0, 3, 3, 0,\n",
              "       0, 4, 0, 0, 0, 1, 0, 3, 3, 0, 0, 3, 2, 0, 0, 3, 3, 3, 0, 0, 0, 3,\n",
              "       0, 1, 4, 0, 0, 2, 2, 2, 0, 0, 3, 4, 0, 2, 0, 0, 3, 0, 2, 0, 3, 0,\n",
              "       0, 1, 3, 0, 0, 3, 0, 2, 0, 0, 3, 0, 0, 2, 0, 3, 4, 0, 0, 1, 0, 0,\n",
              "       3, 3, 0, 0, 0, 0, 0, 2, 4, 0, 0, 4, 0, 0, 2, 0, 0, 0, 0, 1, 2, 0,\n",
              "       2, 2, 2, 0, 3, 3, 2, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 4, 0, 0, 0, 0,\n",
              "       1, 3, 3, 0, 0, 3, 0, 3, 0, 3, 3, 0, 0, 3, 2, 0, 2, 1, 0, 0, 4, 0,\n",
              "       3, 3, 0, 1, 0, 3, 4, 0, 2, 0, 2, 0, 0, 0, 3, 0, 1, 1, 0, 0, 0, 0,\n",
              "       1, 2, 2, 3, 3, 2, 0, 3, 1, 2, 0, 0, 0, 3, 0, 2, 3, 1, 0, 0, 0, 1,\n",
              "       0, 3, 0, 0, 2, 3, 2, 0, 3, 0, 0, 2, 0, 2, 1, 2, 2, 0, 3, 0, 1, 0,\n",
              "       0, 3, 4, 1, 2, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 3, 3,\n",
              "       0, 1, 0, 3, 0, 4, 0, 2, 0, 3, 2, 0, 0, 1, 2, 3, 4, 0, 0, 2, 0, 2,\n",
              "       2, 2, 0, 0, 0, 3, 0, 2, 0, 0, 0, 1, 1, 2, 3, 0, 3, 0, 0, 3, 2, 1,\n",
              "       0, 3, 0, 0, 0, 0, 3, 3, 2, 0, 3, 0, 0, 0, 0, 0, 2, 2, 1, 0, 2, 3,\n",
              "       0, 0, 3, 2, 0, 3, 1, 0, 3, 0, 1, 3, 3, 0, 0, 4, 0, 0, 0, 2, 3, 3,\n",
              "       0, 0, 0, 2, 2, 0, 2, 0, 1, 0, 0, 0, 2, 3, 3, 1, 0, 0, 4, 0, 0, 0,\n",
              "       1, 3, 0, 0, 0, 1, 2, 0, 0, 3, 0, 0, 3, 0, 0, 3, 3, 3, 2, 0, 3, 1,\n",
              "       2, 0, 0, 0, 0, 0, 0, 0, 3, 2, 2, 2, 3, 0, 0, 0, 0, 4, 3, 4, 0, 2,\n",
              "       3, 3, 0, 1, 0, 2, 2, 3, 0, 0, 3, 0, 0, 2, 0, 0, 0, 0, 0, 2, 4, 0,\n",
              "       0, 2, 2, 0, 2, 4, 3, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 3, 0, 0, 0, 0,\n",
              "       0, 0, 3, 2, 3, 0, 0, 0, 0, 0, 0, 1, 3, 0, 0, 2, 0, 3, 3, 2, 0, 0,\n",
              "       3, 2, 3, 0, 0, 0, 3, 0, 0, 0, 3, 3, 0, 3, 1, 0, 0, 0, 2, 0, 0, 0,\n",
              "       1, 3, 3, 0, 2, 3, 0, 2, 0, 3, 3, 3, 0, 3, 0, 0, 2, 2, 4, 0, 0, 3,\n",
              "       2, 3, 0, 1, 0, 2, 0, 0, 0, 1, 3, 1, 3, 0, 3, 0, 2, 2, 2, 0, 2, 3,\n",
              "       0, 3, 0, 1, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 2, 0, 0, 2,\n",
              "       4, 2]), metrics={'test_loss': 0.9046761989593506, 'test_accuracy': 0.6264916467780429, 'test_runtime': 2.5339, 'test_samples_per_second': 330.713, 'test_steps_per_second': 20.916})"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "trainer.predict(test_dataset=tokenized_dataset[\"test\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39HM7iyPT4EJ"
      },
      "source": [
        "#### Saving the model\n",
        "\n",
        "The model can be saved for future loading."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "ZrjZG6HPT4EK",
        "outputId": "1563c582-6cd5-4eaf-e885-3d04d2b035cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to ./results\n",
            "Configuration saved in ./results/config.json\n",
            "Model weights saved in ./results/pytorch_model.bin\n",
            "tokenizer config file saved in ./results/tokenizer_config.json\n",
            "Special tokens file saved in ./results/special_tokens_map.json\n"
          ]
        }
      ],
      "source": [
        "trainer.save_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zx_ex9F5T4EK"
      },
      "source": [
        "#### Loading and using a saved model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "772OqNwMT4EK",
        "outputId": "686e54bb-f59c-4983-f43f-76e9553a8e61",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Didn't find file ./results/added_tokens.json. We won't load it.\n",
            "loading file ./results/vocab.txt\n",
            "loading file ./results/tokenizer.json\n",
            "loading file None\n",
            "loading file ./results/special_tokens_map.json\n",
            "loading file ./results/tokenizer_config.json\n",
            "loading configuration file ./results/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"./results\",\n",
            "  \"architectures\": [\n",
            "    \"BertForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"directionality\": \"bidi\",\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\",\n",
            "    \"4\": \"LABEL_4\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3,\n",
            "    \"LABEL_4\": 4\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_fc_size\": 768,\n",
            "  \"pooler_num_attention_heads\": 12,\n",
            "  \"pooler_num_fc_layers\": 3,\n",
            "  \"pooler_size_per_head\": 128,\n",
            "  \"pooler_type\": \"first_token_transform\",\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"problem_type\": \"single_label_classification\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.19.2\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 29794\n",
            "}\n",
            "\n",
            "loading weights file ./results/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
            "\n",
            "All the weights of BertForSequenceClassification were initialized from the model checkpoint at ./results.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "tokenizer2 = AutoTokenizer.from_pretrained(\"./results\")\n",
        "model2 = AutoModelForSequenceClassification.from_pretrained(\"./results\", num_labels=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egZf7eXxT4EK"
      },
      "source": [
        "To exploit the model, we can use a pipeline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "GCD6BOaiT4EK"
      },
      "outputs": [],
      "source": [
        "from transformers import TextClassificationPipeline\n",
        "\n",
        "pipe = TextClassificationPipeline(model=model2, tokenizer=tokenizer2) #, return_all_scores=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "I_zSIZINT4EK",
        "outputId": "fc05d9b1-6a9e-4d89-dd38-aed487a9c0c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'LABEL_1', 'score': 0.6839435696601868}]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "pipe(\"Considero que a Praxe é muito boa\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8HeeycKT4EL"
      },
      "source": [
        "We can also use the model in a step-by-step fashion, as follows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "DvzgFm9YT4EL",
        "outputId": "176e360f-3795-4978-94ef-381bdf062e89",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': tensor([[  101,  1158,  2776, 22280,   179,   123,  2485,  2650,   253,   785,\n",
            "          3264,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
            "SequenceClassifierOutput(loss=None, logits=tensor([[ 0.8035,  1.9816, -1.2588, -0.4059, -1.7807]],\n",
            "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Value(+)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "inputs = \"Considero que a Praxe é muito boa\"\n",
        "\n",
        "# tokenize inputs\n",
        "tokenized_inputs = tokenizer2(inputs, return_tensors=\"pt\")\n",
        "print(tokenized_inputs)\n",
        "\n",
        "# obtain model outputs\n",
        "outputs = model2(**tokenized_inputs)\n",
        "print(outputs)\n",
        "\n",
        "# get the most likely label\n",
        "labels = ['Value', 'Value(+)', 'Value(-)', 'Fact', 'Policy']\n",
        "prediction = torch.argmax(outputs.logits)\n",
        "print(labels[prediction])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7lRWcskT4EL"
      },
      "source": [
        "Let's check again the performance of the model in the test set, possibly with additional metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "Lg2s4DfsT4EM"
      },
      "outputs": [],
      "source": [
        "y_pred= []\n",
        "for p in tokenized_dataset['test']['tokens']:\n",
        "    ti = tokenizer2(p, return_tensors=\"pt\")\n",
        "    out = model2(**ti)\n",
        "    pred = torch.argmax(out.logits)\n",
        "    y_pred.append(pred)   # our labels are already 0 and 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "Nran3wx4T4EM",
        "outputId": "03631540-773e-49e4-df19-a26644baf6e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[309  22  54  29  11]\n",
            " [ 27  25   2   4   1]\n",
            " [ 30   0 103   5   2]\n",
            " [ 78   9  24  69   0]\n",
            " [ 11   1   2   1  19]]\n",
            "Accuracy:  0.6264916467780429\n",
            "Precision:  0.5778241183504341\n",
            "Recall:  0.5657317571096236\n",
            "F1:  0.5626968419297291\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "y_test = tokenized_dataset['test']['label']\n",
        "\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print('Accuracy: ', accuracy_score(y_test, y_pred))\n",
        "print('Precision: ', precision_score(y_test, y_pred, average='macro'))\n",
        "print('Recall: ', recall_score(y_test, y_pred, average='macro'))\n",
        "print('F1: ', f1_score(y_test, y_pred, average='macro'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WgY2lqt7T4EM"
      },
      "source": [
        "We can do the same using a Trainer, as before."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "6PLabZQWT4EM",
        "outputId": "c6188dcb-00bc-4136-c5ed-deac6cc91fb6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n",
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
          ]
        }
      ],
      "source": [
        "trainer2 = Trainer(\n",
        "    model=model2,\n",
        "    tokenizer=tokenizer2,\n",
        "    compute_metrics=compute_metrics\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "AyLrp1dDT4EM",
        "outputId": "d295334b-9684-4daa-8d99-488664f55e64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 925
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the test set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: tokens. If tokens are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Prediction *****\n",
            "  Num examples = 838\n",
            "  Batch size = 8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='105' max='105' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [105/105 00:02]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PredictionOutput(predictions=array([[ 0.37601352, -1.5194659 ,  2.8067954 ,  0.48898408, -1.9309189 ],\n",
              "       [ 1.3340023 ,  2.0924182 , -1.9254825 , -0.24892056, -1.7757592 ],\n",
              "       [ 0.6551271 , -0.8557426 , -0.7193791 ,  3.2252967 , -2.5290272 ],\n",
              "       ...,\n",
              "       [ 2.8552709 , -1.5310497 ,  0.7302812 ,  1.508096  , -2.8344948 ],\n",
              "       [ 1.3395143 , -0.9876522 , -1.1002288 , -1.0114254 ,  2.6395814 ],\n",
              "       [ 0.7530727 , -1.8906747 ,  3.2568834 ,  0.32288778, -2.2073815 ]],\n",
              "      dtype=float32), label_ids=array([2, 1, 2, 3, 0, 1, 3, 0, 0, 0, 0, 0, 3, 0, 0, 3, 0, 0, 0, 0, 1, 2,\n",
              "       0, 3, 0, 0, 0, 2, 2, 0, 3, 3, 0, 2, 2, 0, 0, 2, 0, 0, 2, 2, 2, 3,\n",
              "       0, 3, 0, 0, 2, 0, 0, 1, 3, 0, 2, 0, 3, 3, 3, 0, 3, 0, 0, 1, 2, 2,\n",
              "       3, 2, 0, 0, 3, 0, 2, 3, 0, 0, 0, 3, 3, 0, 0, 0, 0, 2, 0, 4, 0, 0,\n",
              "       0, 3, 0, 3, 0, 0, 0, 0, 3, 0, 3, 0, 3, 4, 0, 0, 0, 0, 0, 2, 3, 0,\n",
              "       0, 0, 0, 0, 0, 2, 3, 0, 0, 3, 2, 0, 3, 4, 2, 3, 0, 0, 0, 0, 2, 0,\n",
              "       0, 0, 3, 3, 0, 2, 3, 0, 0, 2, 0, 1, 0, 0, 3, 0, 2, 0, 3, 2, 0, 2,\n",
              "       0, 3, 0, 3, 2, 3, 3, 0, 0, 1, 1, 3, 3, 0, 0, 3, 0, 2, 3, 3, 3, 0,\n",
              "       2, 0, 0, 3, 0, 0, 0, 3, 2, 0, 2, 3, 3, 2, 4, 0, 3, 2, 1, 1, 2, 1,\n",
              "       2, 0, 2, 2, 0, 3, 0, 3, 0, 0, 2, 2, 2, 0, 0, 4, 0, 3, 0, 1, 2, 0,\n",
              "       3, 3, 2, 2, 2, 3, 0, 0, 1, 3, 0, 3, 1, 4, 0, 0, 0, 0, 3, 0, 3, 2,\n",
              "       1, 2, 0, 4, 3, 0, 0, 4, 0, 1, 0, 3, 0, 3, 1, 3, 0, 0, 0, 0, 3, 2,\n",
              "       0, 0, 0, 4, 0, 0, 0, 0, 0, 3, 4, 3, 0, 2, 3, 2, 0, 3, 2, 4, 3, 2,\n",
              "       0, 4, 0, 2, 2, 0, 3, 0, 0, 3, 0, 4, 0, 1, 0, 2, 3, 0, 0, 3, 3, 0,\n",
              "       0, 4, 0, 0, 0, 1, 0, 3, 3, 0, 0, 3, 2, 0, 0, 3, 3, 3, 0, 0, 0, 3,\n",
              "       0, 1, 4, 0, 0, 2, 2, 2, 0, 0, 3, 4, 0, 2, 0, 0, 3, 0, 2, 0, 3, 0,\n",
              "       0, 1, 3, 0, 0, 3, 0, 2, 0, 0, 3, 0, 0, 2, 0, 3, 4, 0, 0, 1, 0, 0,\n",
              "       3, 3, 0, 0, 0, 0, 0, 2, 4, 0, 0, 4, 0, 0, 2, 0, 0, 0, 0, 1, 2, 0,\n",
              "       2, 2, 2, 0, 3, 3, 2, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 4, 0, 0, 0, 0,\n",
              "       1, 3, 3, 0, 0, 3, 0, 3, 0, 3, 3, 0, 0, 3, 2, 0, 2, 1, 0, 0, 4, 0,\n",
              "       3, 3, 0, 1, 0, 3, 4, 0, 2, 0, 2, 0, 0, 0, 3, 0, 1, 1, 0, 0, 0, 0,\n",
              "       1, 2, 2, 3, 3, 2, 0, 3, 1, 2, 0, 0, 0, 3, 0, 2, 3, 1, 0, 0, 0, 1,\n",
              "       0, 3, 0, 0, 2, 3, 2, 0, 3, 0, 0, 2, 0, 2, 1, 2, 2, 0, 3, 0, 1, 0,\n",
              "       0, 3, 4, 1, 2, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 3, 3,\n",
              "       0, 1, 0, 3, 0, 4, 0, 2, 0, 3, 2, 0, 0, 1, 2, 3, 4, 0, 0, 2, 0, 2,\n",
              "       2, 2, 0, 0, 0, 3, 0, 2, 0, 0, 0, 1, 1, 2, 3, 0, 3, 0, 0, 3, 2, 1,\n",
              "       0, 3, 0, 0, 0, 0, 3, 3, 2, 0, 3, 0, 0, 0, 0, 0, 2, 2, 1, 0, 2, 3,\n",
              "       0, 0, 3, 2, 0, 3, 1, 0, 3, 0, 1, 3, 3, 0, 0, 4, 0, 0, 0, 2, 3, 3,\n",
              "       0, 0, 0, 2, 2, 0, 2, 0, 1, 0, 0, 0, 2, 3, 3, 1, 0, 0, 4, 0, 0, 0,\n",
              "       1, 3, 0, 0, 0, 1, 2, 0, 0, 3, 0, 0, 3, 0, 0, 3, 3, 3, 2, 0, 3, 1,\n",
              "       2, 0, 0, 0, 0, 0, 0, 0, 3, 2, 2, 2, 3, 0, 0, 0, 0, 4, 3, 4, 0, 2,\n",
              "       3, 3, 0, 1, 0, 2, 2, 3, 0, 0, 3, 0, 0, 2, 0, 0, 0, 0, 0, 2, 4, 0,\n",
              "       0, 2, 2, 0, 2, 4, 3, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 3, 0, 0, 0, 0,\n",
              "       0, 0, 3, 2, 3, 0, 0, 0, 0, 0, 0, 1, 3, 0, 0, 2, 0, 3, 3, 2, 0, 0,\n",
              "       3, 2, 3, 0, 0, 0, 3, 0, 0, 0, 3, 3, 0, 3, 1, 0, 0, 0, 2, 0, 0, 0,\n",
              "       1, 3, 3, 0, 2, 3, 0, 2, 0, 3, 3, 3, 0, 3, 0, 0, 2, 2, 4, 0, 0, 3,\n",
              "       2, 3, 0, 1, 0, 2, 0, 0, 0, 1, 3, 1, 3, 0, 3, 0, 2, 2, 2, 0, 2, 3,\n",
              "       0, 3, 0, 1, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 2, 0, 0, 2,\n",
              "       4, 2]), metrics={'test_loss': 0.9046761393547058, 'test_accuracy': 0.6264916467780429, 'test_runtime': 2.2871, 'test_samples_per_second': 366.396, 'test_steps_per_second': 45.909})"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "trainer2.predict(test_dataset=tokenized_dataset[\"test\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now to try with large"
      ],
      "metadata": {
        "id": "MFCu4DB7htMf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"neuralmind/bert-large-portuguese-cased\"\n",
        "tokenizer = get_tokenizer(model_name)\n",
        "model = get_model(model_name)\n",
        "model.cuda()\n",
        "\n",
        "training_args = get_trainingArgs()\n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "trainer = get_trainer(model,training_args,tokenized_dataset,tokenizer,data_collator,compute_metrics)\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "kvgVwMxRh0bF",
        "outputId": "a4ea025c-0897-48cd-ccc4-cf68af8d05be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "8f873d4ed4be4e299f2dff361e42ae59",
            "d8f6528300b4404cbb5c2013fb26a002",
            "fbf41f25edb444948260358d0094367d",
            "5e15d4927175477e8882ba2bf757b7ff",
            "7ece68b733d1428d903119b954736ebc",
            "11d64f3e5d314f18ae2342bcedd5e238",
            "68d830797b0a46b1813fae11f40df1ae",
            "6a9f2e554a534131b7b08db124f88c38",
            "01a6932e788543b2982ebf707cc706f8",
            "40c898b2d025458f9ae5503790ab9f14",
            "d2522c9d2fd946c4920da1c3e3a07bde",
            "15d1239ad0a244099a29349621dc5628",
            "7f5fd7e0aa3745318bef6c9060340db4",
            "467eea54606144b9a2603c31ac821f9a",
            "87624c2bec054913a3555acfcf5fdc62",
            "3844a673b5dd4be99096c36b383b4c91",
            "1552832df2ae41748171bd48bd972f54",
            "ac482944bbd9433089a9c614f2fe13af",
            "4130da3f372b4a1481132c55846a0137",
            "660d9f0d95da47cd9c73b31f2817b059",
            "03d8ad78f92441c09d914ce13b6b9b2f",
            "661861efeb0c48dea14281d2d098fdfb",
            "1a52b9ac88164fa1a6c0958d111b5df5",
            "9d368e0f244e4961b35470f93ec1c3e0",
            "82ce402f2c36491db0834776798d2c39",
            "900a330866c24c94afa95afe47633316",
            "04967cfae21144bfbd9a15cc0ee23652",
            "afc5f8cd4b3c4f01811c7c95c1fb001b",
            "40dfb5575a5a429fad2585907df0d8c7",
            "7dc56408d8a6407fa5c2088290900706",
            "60c7692b7f1a47ac89ca344ef009df48",
            "8befc173fda24be38c6929e825888e8b",
            "d2d5ec624b9e42c69f8cc1eb3bca7997",
            "ceed78d1d09b49ea83aa90457b8290b0",
            "ad6dbaf62ce5402b8a2a17285316665e",
            "be2b738159fd41ec9c69a711db8a7bb6",
            "630d4d7334984f2186620868fbc682a0",
            "a195560bc9d44e67a70aec6f9097f5a4",
            "5fce26a2ab43462b9972d7da48ab406d",
            "1b471337448c4f118823ec3109652186",
            "7fe54986c3474c2bb79d75510785a6d6",
            "aad94ba6acf2479b873d0f898acf4083",
            "5606eecc3b5f40eaaf4e99087153e185",
            "b7da6e09530d46a4a34d77f698724158",
            "afd9952998114ce19e96dba92b2a1343",
            "43ed4ed1c4c04cf48b6b9733cf27bc5b",
            "7d8b6ac5b3eb4e4caa3aa0095fa1c9a0",
            "a1aa5ff8d011486f81e37e9c0f45e783",
            "9e038e29162b4c3885c8bf737d73253c",
            "b29dee7aa02a4ddd929956559b34c132",
            "3a64a0b392804f269c449f6b47205376",
            "ec3d262681014415947f0530a74da919",
            "d0fa96a64c5541b08edea29a7737fd1a",
            "a7a66d4927fc409dbcf031519abf02a0",
            "8c180b9c52314cc883629033453b806e",
            "a1d9f7da46394d82b706516608aa40ed",
            "04145ae3b39d446c9e452daedf10425f",
            "462620b853be453a91df73f751a18481",
            "4717a02dcc25487fa2d701334346de14",
            "a2826375b76e445380679747595a4b4a",
            "0593c216a3be44ab87961835dd488358",
            "5b749e529b4948999a7832bd8e8503b3",
            "ce897a98d3c24d1988d5f4eed8ca94aa",
            "a541e10f444b4b8298d74ddc5a1c0147",
            "c955bf3510624995a4229794e71549e0",
            "561abd6ac5374ccd8df59f0ad0d21743"
          ]
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "https://huggingface.co/neuralmind/bert-large-portuguese-cased/resolve/main/tokenizer_config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp5b4h7ekx\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/155 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8f873d4ed4be4e299f2dff361e42ae59"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "storing https://huggingface.co/neuralmind/bert-large-portuguese-cased/resolve/main/tokenizer_config.json in cache at /root/.cache/huggingface/transformers/3a44fa9a74e90f509368a7f2789df38e1fedd153a52c62ef5cc5f4b0f5c99c2a.d61b68f744aef2741575c270d4ba0228cd35693bfa15d8babfb5c1079062d5d7\n",
            "creating metadata file for /root/.cache/huggingface/transformers/3a44fa9a74e90f509368a7f2789df38e1fedd153a52c62ef5cc5f4b0f5c99c2a.d61b68f744aef2741575c270d4ba0228cd35693bfa15d8babfb5c1079062d5d7\n",
            "https://huggingface.co/neuralmind/bert-large-portuguese-cased/resolve/main/config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpekxwjydm\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/648 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "15d1239ad0a244099a29349621dc5628"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "storing https://huggingface.co/neuralmind/bert-large-portuguese-cased/resolve/main/config.json in cache at /root/.cache/huggingface/transformers/c534071830642050813fa94003dbf1234413b3f1d5dc66d259fbc82ff7d5fd59.c8340a82acfbbcd2dd960b86d2886ee120b21896ef0294150f0391918ae6ced5\n",
            "creating metadata file for /root/.cache/huggingface/transformers/c534071830642050813fa94003dbf1234413b3f1d5dc66d259fbc82ff7d5fd59.c8340a82acfbbcd2dd960b86d2886ee120b21896ef0294150f0391918ae6ced5\n",
            "loading configuration file https://huggingface.co/neuralmind/bert-large-portuguese-cased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/c534071830642050813fa94003dbf1234413b3f1d5dc66d259fbc82ff7d5fd59.c8340a82acfbbcd2dd960b86d2886ee120b21896ef0294150f0391918ae6ced5\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"neuralmind/bert-large-portuguese-cased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"directionality\": \"bidi\",\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 4096,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_fc_size\": 768,\n",
            "  \"pooler_num_attention_heads\": 12,\n",
            "  \"pooler_num_fc_layers\": 3,\n",
            "  \"pooler_size_per_head\": 128,\n",
            "  \"pooler_type\": \"first_token_transform\",\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.19.2\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 29794\n",
            "}\n",
            "\n",
            "https://huggingface.co/neuralmind/bert-large-portuguese-cased/resolve/main/vocab.txt not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp9lfgj5k0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/205k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1a52b9ac88164fa1a6c0958d111b5df5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "storing https://huggingface.co/neuralmind/bert-large-portuguese-cased/resolve/main/vocab.txt in cache at /root/.cache/huggingface/transformers/9cfcd25de0a333b1b5f4a3db227e93a806cfb041d93a49221eeaee6773eaa41c.af25fb1e29ad0175300146695fd80069be69b211c52fa5486fa8aae2754cc814\n",
            "creating metadata file for /root/.cache/huggingface/transformers/9cfcd25de0a333b1b5f4a3db227e93a806cfb041d93a49221eeaee6773eaa41c.af25fb1e29ad0175300146695fd80069be69b211c52fa5486fa8aae2754cc814\n",
            "https://huggingface.co/neuralmind/bert-large-portuguese-cased/resolve/main/added_tokens.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpgh16e7j2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ceed78d1d09b49ea83aa90457b8290b0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "storing https://huggingface.co/neuralmind/bert-large-portuguese-cased/resolve/main/added_tokens.json in cache at /root/.cache/huggingface/transformers/6a3aa038873b8f0d0ab3a4de0a658f063b89e3afd815920a5f393c0e4ae84259.5cc6e825eb228a7a5cfd27cb4d7151e97a79fb962b31aaf1813aa102e746584b\n",
            "creating metadata file for /root/.cache/huggingface/transformers/6a3aa038873b8f0d0ab3a4de0a658f063b89e3afd815920a5f393c0e4ae84259.5cc6e825eb228a7a5cfd27cb4d7151e97a79fb962b31aaf1813aa102e746584b\n",
            "https://huggingface.co/neuralmind/bert-large-portuguese-cased/resolve/main/special_tokens_map.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpam1_v_5t\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "afd9952998114ce19e96dba92b2a1343"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "storing https://huggingface.co/neuralmind/bert-large-portuguese-cased/resolve/main/special_tokens_map.json in cache at /root/.cache/huggingface/transformers/d5b721c156180bbbcc4a1017e8c72a18f8f96cdc178acec5ddcd45905712b4cf.dd8bd9bfd3664b530ea4e645105f557769387b3da9f79bdb55ed556bdd80611d\n",
            "creating metadata file for /root/.cache/huggingface/transformers/d5b721c156180bbbcc4a1017e8c72a18f8f96cdc178acec5ddcd45905712b4cf.dd8bd9bfd3664b530ea4e645105f557769387b3da9f79bdb55ed556bdd80611d\n",
            "loading file https://huggingface.co/neuralmind/bert-large-portuguese-cased/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/9cfcd25de0a333b1b5f4a3db227e93a806cfb041d93a49221eeaee6773eaa41c.af25fb1e29ad0175300146695fd80069be69b211c52fa5486fa8aae2754cc814\n",
            "loading file https://huggingface.co/neuralmind/bert-large-portuguese-cased/resolve/main/tokenizer.json from cache at None\n",
            "loading file https://huggingface.co/neuralmind/bert-large-portuguese-cased/resolve/main/added_tokens.json from cache at /root/.cache/huggingface/transformers/6a3aa038873b8f0d0ab3a4de0a658f063b89e3afd815920a5f393c0e4ae84259.5cc6e825eb228a7a5cfd27cb4d7151e97a79fb962b31aaf1813aa102e746584b\n",
            "loading file https://huggingface.co/neuralmind/bert-large-portuguese-cased/resolve/main/special_tokens_map.json from cache at /root/.cache/huggingface/transformers/d5b721c156180bbbcc4a1017e8c72a18f8f96cdc178acec5ddcd45905712b4cf.dd8bd9bfd3664b530ea4e645105f557769387b3da9f79bdb55ed556bdd80611d\n",
            "loading file https://huggingface.co/neuralmind/bert-large-portuguese-cased/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/3a44fa9a74e90f509368a7f2789df38e1fedd153a52c62ef5cc5f4b0f5c99c2a.d61b68f744aef2741575c270d4ba0228cd35693bfa15d8babfb5c1079062d5d7\n",
            "loading configuration file https://huggingface.co/neuralmind/bert-large-portuguese-cased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/c534071830642050813fa94003dbf1234413b3f1d5dc66d259fbc82ff7d5fd59.c8340a82acfbbcd2dd960b86d2886ee120b21896ef0294150f0391918ae6ced5\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"neuralmind/bert-large-portuguese-cased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"directionality\": \"bidi\",\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 4096,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_fc_size\": 768,\n",
            "  \"pooler_num_attention_heads\": 12,\n",
            "  \"pooler_num_fc_layers\": 3,\n",
            "  \"pooler_size_per_head\": 128,\n",
            "  \"pooler_type\": \"first_token_transform\",\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.19.2\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 29794\n",
            "}\n",
            "\n",
            "loading configuration file https://huggingface.co/neuralmind/bert-large-portuguese-cased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/c534071830642050813fa94003dbf1234413b3f1d5dc66d259fbc82ff7d5fd59.c8340a82acfbbcd2dd960b86d2886ee120b21896ef0294150f0391918ae6ced5\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"neuralmind/bert-large-portuguese-cased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"directionality\": \"bidi\",\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 4096,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_fc_size\": 768,\n",
            "  \"pooler_num_attention_heads\": 12,\n",
            "  \"pooler_num_fc_layers\": 3,\n",
            "  \"pooler_size_per_head\": 128,\n",
            "  \"pooler_type\": \"first_token_transform\",\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.19.2\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 29794\n",
            "}\n",
            "\n",
            "loading configuration file https://huggingface.co/neuralmind/bert-large-portuguese-cased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/c534071830642050813fa94003dbf1234413b3f1d5dc66d259fbc82ff7d5fd59.c8340a82acfbbcd2dd960b86d2886ee120b21896ef0294150f0391918ae6ced5\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"neuralmind/bert-large-portuguese-cased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"directionality\": \"bidi\",\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\",\n",
            "    \"4\": \"LABEL_4\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 4096,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3,\n",
            "    \"LABEL_4\": 4\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_fc_size\": 768,\n",
            "  \"pooler_num_attention_heads\": 12,\n",
            "  \"pooler_num_fc_layers\": 3,\n",
            "  \"pooler_size_per_head\": 128,\n",
            "  \"pooler_type\": \"first_token_transform\",\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.19.2\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 29794\n",
            "}\n",
            "\n",
            "https://huggingface.co/neuralmind/bert-large-portuguese-cased/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp7tlxrf9m\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.25G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a1d9f7da46394d82b706516608aa40ed"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "storing https://huggingface.co/neuralmind/bert-large-portuguese-cased/resolve/main/pytorch_model.bin in cache at /root/.cache/huggingface/transformers/016fb7702039667c9fb9dd2ceffaf04027b13e525a6248cda2a4a87dbb8687af.881d7200bce807f871637ac9d552c541b2d4b00146a0bf1ab0360f3640031273\n",
            "creating metadata file for /root/.cache/huggingface/transformers/016fb7702039667c9fb9dd2ceffaf04027b13e525a6248cda2a4a87dbb8687af.881d7200bce807f871637ac9d552c541b2d4b00146a0bf1ab0360f3640031273\n",
            "loading weights file https://huggingface.co/neuralmind/bert-large-portuguese-cased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/016fb7702039667c9fb9dd2ceffaf04027b13e525a6248cda2a4a87dbb8687af.881d7200bce807f871637ac9d552c541b2d4b00146a0bf1ab0360f3640031273\n",
            "Some weights of the model checkpoint at neuralmind/bert-large-portuguese-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at neuralmind/bert-large-portuguese-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: tokens. If tokens are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 15068\n",
            "  Num Epochs = 10\n",
            "  Instantaneous batch size per device = 16\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 9420\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='9420' max='9420' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [9420/9420 1:32:05, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.055500</td>\n",
              "      <td>0.907356</td>\n",
              "      <td>0.612903</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.746300</td>\n",
              "      <td>0.906321</td>\n",
              "      <td>0.634409</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.572000</td>\n",
              "      <td>1.070370</td>\n",
              "      <td>0.608124</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.461100</td>\n",
              "      <td>1.188678</td>\n",
              "      <td>0.585424</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.395300</td>\n",
              "      <td>1.261466</td>\n",
              "      <td>0.592593</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.352500</td>\n",
              "      <td>1.525894</td>\n",
              "      <td>0.586619</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.306400</td>\n",
              "      <td>1.691817</td>\n",
              "      <td>0.593787</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.269100</td>\n",
              "      <td>1.826676</td>\n",
              "      <td>0.587814</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.221600</td>\n",
              "      <td>2.081511</td>\n",
              "      <td>0.579450</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.199900</td>\n",
              "      <td>2.230173</td>\n",
              "      <td>0.577061</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: tokens. If tokens are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 837\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to ./results/checkpoint-942\n",
            "Configuration saved in ./results/checkpoint-942/config.json\n",
            "Model weights saved in ./results/checkpoint-942/pytorch_model.bin\n",
            "tokenizer config file saved in ./results/checkpoint-942/tokenizer_config.json\n",
            "Special tokens file saved in ./results/checkpoint-942/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: tokens. If tokens are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 837\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to ./results/checkpoint-1884\n",
            "Configuration saved in ./results/checkpoint-1884/config.json\n",
            "Model weights saved in ./results/checkpoint-1884/pytorch_model.bin\n",
            "tokenizer config file saved in ./results/checkpoint-1884/tokenizer_config.json\n",
            "Special tokens file saved in ./results/checkpoint-1884/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: tokens. If tokens are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 837\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to ./results/checkpoint-2826\n",
            "Configuration saved in ./results/checkpoint-2826/config.json\n",
            "Model weights saved in ./results/checkpoint-2826/pytorch_model.bin\n",
            "tokenizer config file saved in ./results/checkpoint-2826/tokenizer_config.json\n",
            "Special tokens file saved in ./results/checkpoint-2826/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: tokens. If tokens are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 837\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to ./results/checkpoint-3768\n",
            "Configuration saved in ./results/checkpoint-3768/config.json\n",
            "Model weights saved in ./results/checkpoint-3768/pytorch_model.bin\n",
            "tokenizer config file saved in ./results/checkpoint-3768/tokenizer_config.json\n",
            "Special tokens file saved in ./results/checkpoint-3768/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: tokens. If tokens are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 837\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to ./results/checkpoint-4710\n",
            "Configuration saved in ./results/checkpoint-4710/config.json\n",
            "Model weights saved in ./results/checkpoint-4710/pytorch_model.bin\n",
            "tokenizer config file saved in ./results/checkpoint-4710/tokenizer_config.json\n",
            "Special tokens file saved in ./results/checkpoint-4710/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: tokens. If tokens are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 837\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to ./results/checkpoint-5652\n",
            "Configuration saved in ./results/checkpoint-5652/config.json\n",
            "Model weights saved in ./results/checkpoint-5652/pytorch_model.bin\n",
            "tokenizer config file saved in ./results/checkpoint-5652/tokenizer_config.json\n",
            "Special tokens file saved in ./results/checkpoint-5652/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: tokens. If tokens are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 837\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to ./results/checkpoint-6594\n",
            "Configuration saved in ./results/checkpoint-6594/config.json\n",
            "Model weights saved in ./results/checkpoint-6594/pytorch_model.bin\n",
            "tokenizer config file saved in ./results/checkpoint-6594/tokenizer_config.json\n",
            "Special tokens file saved in ./results/checkpoint-6594/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: tokens. If tokens are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 837\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to ./results/checkpoint-7536\n",
            "Configuration saved in ./results/checkpoint-7536/config.json\n",
            "Model weights saved in ./results/checkpoint-7536/pytorch_model.bin\n",
            "tokenizer config file saved in ./results/checkpoint-7536/tokenizer_config.json\n",
            "Special tokens file saved in ./results/checkpoint-7536/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: tokens. If tokens are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 837\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to ./results/checkpoint-8478\n",
            "Configuration saved in ./results/checkpoint-8478/config.json\n",
            "Model weights saved in ./results/checkpoint-8478/pytorch_model.bin\n",
            "tokenizer config file saved in ./results/checkpoint-8478/tokenizer_config.json\n",
            "Special tokens file saved in ./results/checkpoint-8478/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: tokens. If tokens are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 837\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to ./results/checkpoint-9420\n",
            "Configuration saved in ./results/checkpoint-9420/config.json\n",
            "Model weights saved in ./results/checkpoint-9420/pytorch_model.bin\n",
            "tokenizer config file saved in ./results/checkpoint-9420/tokenizer_config.json\n",
            "Special tokens file saved in ./results/checkpoint-9420/special_tokens_map.json\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from ./results/checkpoint-1884 (score: 0.9063213467597961).\n",
            "Could not locate the best model at ./results/checkpoint-1884/pytorch_model.bin, if you are running a distributed training on multiple nodes, you should activate `--save_on_each_node`.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=9420, training_loss=0.4522808690486187, metrics={'train_runtime': 5526.3998, 'train_samples_per_second': 27.265, 'train_steps_per_second': 1.705, 'total_flos': 1.3485700452682056e+16, 'train_loss': 0.4522808690486187, 'epoch': 10.0})"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.evaluate()"
      ],
      "metadata": {
        "id": "WNDxO8e2iB39",
        "outputId": "4c609479-8eed-4482-f32f-f5ede1afcc3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: tokens. If tokens are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 837\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='53' max='53' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [53/53 00:08]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'epoch': 10.0,\n",
              " 'eval_accuracy': 0.5770609318996416,\n",
              " 'eval_loss': 2.230172634124756,\n",
              " 'eval_runtime': 8.7223,\n",
              " 'eval_samples_per_second': 95.961,\n",
              " 'eval_steps_per_second': 6.076}"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.predict(test_dataset=tokenized_dataset[\"test\"])"
      ],
      "metadata": {
        "id": "GO0DABCiiEjd",
        "outputId": "ad52fd2e-cf5f-467b-9f18-472bea2b93db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 925
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the test set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: tokens. If tokens are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Prediction *****\n",
            "  Num examples = 838\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='106' max='53' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [53/53 00:16]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PredictionOutput(predictions=array([[-2.1547718 , -2.7671638 ,  7.155498  , -0.11752454, -1.8404052 ],\n",
              "       [ 2.8251185 ,  4.594569  , -3.5549378 , -2.374643  , -2.850478  ],\n",
              "       [-4.315672  ,  1.159939  , -2.0939956 ,  6.453194  , -1.1730695 ],\n",
              "       ...,\n",
              "       [ 7.499666  , -2.3837373 , -2.1279833 , -1.7322022 , -1.741272  ],\n",
              "       [ 2.9533944 , -3.6260717 , -0.3390447 , -2.8510425 ,  3.8079016 ],\n",
              "       [-4.0607533 , -1.186632  ,  0.9396547 ,  6.576129  , -1.6154824 ]],\n",
              "      dtype=float32), label_ids=array([2, 1, 2, 3, 0, 1, 3, 0, 0, 0, 0, 0, 3, 0, 0, 3, 0, 0, 0, 0, 1, 2,\n",
              "       0, 3, 0, 0, 0, 2, 2, 0, 3, 3, 0, 2, 2, 0, 0, 2, 0, 0, 2, 2, 2, 3,\n",
              "       0, 3, 0, 0, 2, 0, 0, 1, 3, 0, 2, 0, 3, 3, 3, 0, 3, 0, 0, 1, 2, 2,\n",
              "       3, 2, 0, 0, 3, 0, 2, 3, 0, 0, 0, 3, 3, 0, 0, 0, 0, 2, 0, 4, 0, 0,\n",
              "       0, 3, 0, 3, 0, 0, 0, 0, 3, 0, 3, 0, 3, 4, 0, 0, 0, 0, 0, 2, 3, 0,\n",
              "       0, 0, 0, 0, 0, 2, 3, 0, 0, 3, 2, 0, 3, 4, 2, 3, 0, 0, 0, 0, 2, 0,\n",
              "       0, 0, 3, 3, 0, 2, 3, 0, 0, 2, 0, 1, 0, 0, 3, 0, 2, 0, 3, 2, 0, 2,\n",
              "       0, 3, 0, 3, 2, 3, 3, 0, 0, 1, 1, 3, 3, 0, 0, 3, 0, 2, 3, 3, 3, 0,\n",
              "       2, 0, 0, 3, 0, 0, 0, 3, 2, 0, 2, 3, 3, 2, 4, 0, 3, 2, 1, 1, 2, 1,\n",
              "       2, 0, 2, 2, 0, 3, 0, 3, 0, 0, 2, 2, 2, 0, 0, 4, 0, 3, 0, 1, 2, 0,\n",
              "       3, 3, 2, 2, 2, 3, 0, 0, 1, 3, 0, 3, 1, 4, 0, 0, 0, 0, 3, 0, 3, 2,\n",
              "       1, 2, 0, 4, 3, 0, 0, 4, 0, 1, 0, 3, 0, 3, 1, 3, 0, 0, 0, 0, 3, 2,\n",
              "       0, 0, 0, 4, 0, 0, 0, 0, 0, 3, 4, 3, 0, 2, 3, 2, 0, 3, 2, 4, 3, 2,\n",
              "       0, 4, 0, 2, 2, 0, 3, 0, 0, 3, 0, 4, 0, 1, 0, 2, 3, 0, 0, 3, 3, 0,\n",
              "       0, 4, 0, 0, 0, 1, 0, 3, 3, 0, 0, 3, 2, 0, 0, 3, 3, 3, 0, 0, 0, 3,\n",
              "       0, 1, 4, 0, 0, 2, 2, 2, 0, 0, 3, 4, 0, 2, 0, 0, 3, 0, 2, 0, 3, 0,\n",
              "       0, 1, 3, 0, 0, 3, 0, 2, 0, 0, 3, 0, 0, 2, 0, 3, 4, 0, 0, 1, 0, 0,\n",
              "       3, 3, 0, 0, 0, 0, 0, 2, 4, 0, 0, 4, 0, 0, 2, 0, 0, 0, 0, 1, 2, 0,\n",
              "       2, 2, 2, 0, 3, 3, 2, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 4, 0, 0, 0, 0,\n",
              "       1, 3, 3, 0, 0, 3, 0, 3, 0, 3, 3, 0, 0, 3, 2, 0, 2, 1, 0, 0, 4, 0,\n",
              "       3, 3, 0, 1, 0, 3, 4, 0, 2, 0, 2, 0, 0, 0, 3, 0, 1, 1, 0, 0, 0, 0,\n",
              "       1, 2, 2, 3, 3, 2, 0, 3, 1, 2, 0, 0, 0, 3, 0, 2, 3, 1, 0, 0, 0, 1,\n",
              "       0, 3, 0, 0, 2, 3, 2, 0, 3, 0, 0, 2, 0, 2, 1, 2, 2, 0, 3, 0, 1, 0,\n",
              "       0, 3, 4, 1, 2, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 3, 3,\n",
              "       0, 1, 0, 3, 0, 4, 0, 2, 0, 3, 2, 0, 0, 1, 2, 3, 4, 0, 0, 2, 0, 2,\n",
              "       2, 2, 0, 0, 0, 3, 0, 2, 0, 0, 0, 1, 1, 2, 3, 0, 3, 0, 0, 3, 2, 1,\n",
              "       0, 3, 0, 0, 0, 0, 3, 3, 2, 0, 3, 0, 0, 0, 0, 0, 2, 2, 1, 0, 2, 3,\n",
              "       0, 0, 3, 2, 0, 3, 1, 0, 3, 0, 1, 3, 3, 0, 0, 4, 0, 0, 0, 2, 3, 3,\n",
              "       0, 0, 0, 2, 2, 0, 2, 0, 1, 0, 0, 0, 2, 3, 3, 1, 0, 0, 4, 0, 0, 0,\n",
              "       1, 3, 0, 0, 0, 1, 2, 0, 0, 3, 0, 0, 3, 0, 0, 3, 3, 3, 2, 0, 3, 1,\n",
              "       2, 0, 0, 0, 0, 0, 0, 0, 3, 2, 2, 2, 3, 0, 0, 0, 0, 4, 3, 4, 0, 2,\n",
              "       3, 3, 0, 1, 0, 2, 2, 3, 0, 0, 3, 0, 0, 2, 0, 0, 0, 0, 0, 2, 4, 0,\n",
              "       0, 2, 2, 0, 2, 4, 3, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 3, 0, 0, 0, 0,\n",
              "       0, 0, 3, 2, 3, 0, 0, 0, 0, 0, 0, 1, 3, 0, 0, 2, 0, 3, 3, 2, 0, 0,\n",
              "       3, 2, 3, 0, 0, 0, 3, 0, 0, 0, 3, 3, 0, 3, 1, 0, 0, 0, 2, 0, 0, 0,\n",
              "       1, 3, 3, 0, 2, 3, 0, 2, 0, 3, 3, 3, 0, 3, 0, 0, 2, 2, 4, 0, 0, 3,\n",
              "       2, 3, 0, 1, 0, 2, 0, 0, 0, 1, 3, 1, 3, 0, 3, 0, 2, 2, 2, 0, 2, 3,\n",
              "       0, 3, 0, 1, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 2, 0, 0, 2,\n",
              "       4, 2]), metrics={'test_loss': 2.0511434078216553, 'test_accuracy': 0.5966587112171837, 'test_runtime': 8.03, 'test_samples_per_second': 104.358, 'test_steps_per_second': 6.6})"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save_model()"
      ],
      "metadata": {
        "id": "AO_2Wl41iW0s",
        "outputId": "de2c16ab-4aee-4532-d3d9-3a8f5173420a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to ./results\n",
            "Configuration saved in ./results/config.json\n",
            "Model weights saved in ./results/pytorch_model.bin\n",
            "tokenizer config file saved in ./results/tokenizer_config.json\n",
            "Special tokens file saved in ./results/special_tokens_map.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "tokenizer2 = AutoTokenizer.from_pretrained(\"./results\")\n",
        "model2 = AutoModelForSequenceClassification.from_pretrained(\"./results\", num_labels=5)\n",
        "\n",
        "from transformers import TextClassificationPipeline\n",
        "\n",
        "pipe = TextClassificationPipeline(model=model2, tokenizer=tokenizer2) #, return_all_scores=True)\n",
        "\n",
        "import torch\n",
        "\n",
        "inputs = \"I consider that this class is great\"\n",
        "\n",
        "# tokenize inputs\n",
        "tokenized_inputs = tokenizer2(inputs, return_tensors=\"pt\")\n",
        "print(tokenized_inputs)\n",
        "\n",
        "# obtain model outputs\n",
        "outputs = model2(**tokenized_inputs)\n",
        "print(outputs)\n",
        "\n",
        "# get the most likely label\n",
        "labels = ['Value', 'Value(+)', 'Value(-)', 'Fact', 'Policy']\n",
        "prediction = torch.argmax(outputs.logits)\n",
        "print(labels[prediction])"
      ],
      "metadata": {
        "id": "gBdIbXPyiWE9",
        "outputId": "eaac6407-1935-4cbf-a081-07b1e78a512b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Didn't find file ./results/added_tokens.json. We won't load it.\n",
            "loading file ./results/vocab.txt\n",
            "loading file ./results/tokenizer.json\n",
            "loading file None\n",
            "loading file ./results/special_tokens_map.json\n",
            "loading file ./results/tokenizer_config.json\n",
            "loading configuration file ./results/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"./results\",\n",
            "  \"architectures\": [\n",
            "    \"BertForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"directionality\": \"bidi\",\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\",\n",
            "    \"4\": \"LABEL_4\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 4096,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3,\n",
            "    \"LABEL_4\": 4\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_fc_size\": 768,\n",
            "  \"pooler_num_attention_heads\": 12,\n",
            "  \"pooler_num_fc_layers\": 3,\n",
            "  \"pooler_size_per_head\": 128,\n",
            "  \"pooler_type\": \"first_token_transform\",\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"problem_type\": \"single_label_classification\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.19.2\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 29794\n",
            "}\n",
            "\n",
            "loading weights file ./results/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
            "\n",
            "All the weights of BertForSequenceClassification were initialized from the model checkpoint at ./results.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': tensor([[  101,   290,  4747, 12230,   352, 12230,   145,  1548,   847,  2498,\n",
            "           352,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
            "SequenceClassifierOutput(loss=None, logits=tensor([[ 5.3657, -2.2033, -2.5468,  0.7432, -1.9797]],\n",
            "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Value\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "op-eHU65T4EM"
      },
      "source": [
        "## Translating to english and using distilbert-base-uncased-finetuned-sst-2-english"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PdkNemsUT4EN"
      },
      "source": [
        "### Translate Text\n",
        "\n",
        "First, translate all tokens:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "ij8jxY-hT4EN",
        "outputId": "595f3a32-d2b6-4edc-834d-77729984a4ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              tokens  label\n",
              "0       The fact is not just the result of ignorance      0\n",
              "1  there was more journalism in his humor (more i...      0\n",
              "2                           It's all comical in FIFA      0\n",
              "3  what we all allow this organization to do is u...      0\n",
              "4  do not make us laugh at the expense of the pow...      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0a91f339-2732-4779-b870-f48a8d1fdbc4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tokens</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The fact is not just the result of ignorance</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>there was more journalism in his humor (more i...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>It's all comical in FIFA</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>what we all allow this organization to do is u...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>do not make us laugh at the expense of the pow...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0a91f339-2732-4779-b870-f48a8d1fdbc4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0a91f339-2732-4779-b870-f48a8d1fdbc4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0a91f339-2732-4779-b870-f48a8d1fdbc4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Importing the dataset\n",
        "dataset = pd.read_excel(\"./data/OpArticles_ADUs_translated.xlsx\")\n",
        "\n",
        "dataset.drop(['article_id', 'annotator', 'node','ranges'], axis=1, inplace=True)\n",
        "dataset['label'].replace(['Value', 'Value(+)', 'Value(-)', 'fact', 'policy'],[0,1,2,3,4], inplace=True)\n",
        "\n",
        "dataset.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "vnZDOE6XT4EN"
      },
      "outputs": [],
      "source": [
        "from datasets import Dataset\n",
        "\n",
        "dataset_hf = Dataset.from_pandas(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "x5gTrnS8T4EN"
      },
      "outputs": [],
      "source": [
        "from datasets import DatasetDict\n",
        "\n",
        "# 90% train, 10% test+validation\n",
        "train_test = dataset_hf.train_test_split(test_size=0.1)\n",
        "\n",
        "# Split the 10% test+validation set in half test, half validation\n",
        "valid_test = train_test['test'].train_test_split(test_size=0.5)\n",
        "\n",
        "# gather everyone if you want to have a single DatasetDict\n",
        "train_valid_test_dataset = DatasetDict({\n",
        "    'train': train_test['train'],\n",
        "    'validation': valid_test['train'],\n",
        "    'test': valid_test['test']\n",
        "})\n",
        "\n",
        "model_name = \"distilbert-base-uncased\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WBmgRQ1RT4EN"
      },
      "source": [
        "### Tokenizer\n",
        "\n",
        "We first load the tokenizer for our model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "mjJ15mOuT4EN",
        "outputId": "13ea8172-0799-41ab-a5c1-d7d8a9983100",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333\n",
            "Model config DistilBertConfig {\n",
            "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
            "  \"activation\": \"gelu\",\n",
            "  \"architectures\": [\n",
            "    \"DistilBertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"dim\": 768,\n",
            "  \"dropout\": 0.1,\n",
            "  \"hidden_dim\": 3072,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"distilbert\",\n",
            "  \"n_heads\": 12,\n",
            "  \"n_layers\": 6,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"qa_dropout\": 0.1,\n",
            "  \"seq_classif_dropout\": 0.2,\n",
            "  \"sinusoidal_pos_embds\": false,\n",
            "  \"tie_weights_\": true,\n",
            "  \"transformers_version\": \"4.19.2\",\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading file https://huggingface.co/distilbert-base-uncased/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/0e1bbfda7f63a99bb52e3915dcf10c3c92122b827d92eb2d34ce94ee79ba486c.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
            "loading file https://huggingface.co/distilbert-base-uncased/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/75abb59d7a06f4f640158a9bfcde005264e59e8d566781ab1415b139d2e4c603.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n",
            "loading file https://huggingface.co/distilbert-base-uncased/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/distilbert-base-uncased/resolve/main/special_tokens_map.json from cache at None\n",
            "loading file https://huggingface.co/distilbert-base-uncased/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/8c8624b8ac8aa99c60c912161f8332de003484428c47906d7ff7eb7f73eecdbb.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
            "loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333\n",
            "Model config DistilBertConfig {\n",
            "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
            "  \"activation\": \"gelu\",\n",
            "  \"architectures\": [\n",
            "    \"DistilBertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"dim\": 768,\n",
            "  \"dropout\": 0.1,\n",
            "  \"hidden_dim\": 3072,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"distilbert\",\n",
            "  \"n_heads\": 12,\n",
            "  \"n_layers\": 6,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"qa_dropout\": 0.1,\n",
            "  \"seq_classif_dropout\": 0.2,\n",
            "  \"sinusoidal_pos_embds\": false,\n",
            "  \"tie_weights_\": true,\n",
            "  \"transformers_version\": \"4.19.2\",\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = get_tokenizer(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "EIfbHvTeT4EO",
        "outputId": "245e362f-7319-498e-b3d7-09cbedff1692",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 148,
          "referenced_widgets": [
            "ff967abf058b4770b12ccd5f68851ffe",
            "96ddaeef13b146409ff3a9cdd914e1d2",
            "9cbcc8cd2cd14eb1b9ae21402fd4c27d",
            "bf51904065314de48222a4a3c9020c53",
            "3557f09c6b81438595837a502bae39f1",
            "8ad7e3ae59b74c848fb5cee7eea29201",
            "25f24252c96340f19559727cfb3de776",
            "9a990af301ed4daaa03937b94f56ca12",
            "1fc46561e9b6418daa5fa229ec701fe2",
            "aabc039785f742e1bda7102b11ac0a59",
            "192ddacd94bb459da666403792a7192b",
            "d6506b95c0424f308fc8dab31f1c6a72",
            "999bc93380c14d0086358eaa86bb7131",
            "26d66b4a5d044ce0abd9ab194db3aeac",
            "338c8d8248fd4c5d854137db971cee01",
            "bdb88938c8f1469aa76a645822a783ea",
            "191c9f16792f4259be8948f235a9d594",
            "1134dc3850a34d4e951586776ab7fe92",
            "6b3945a2d8c34e95b61ee3a332a2e6b6",
            "7e9a23a0f9aa4d9ba918292b7a2fcffb",
            "7fa78fb01ec94dfdab62f988701cf170",
            "8f47f01e5f3744ed860abf4d05e66372",
            "b4f5c93141a84d5e988fafd847579de3",
            "1e4be27655be4ec19516fa97d8ff5c0c",
            "a72a252abd9d4df9801d6cc1e057790d",
            "6c150ed4152047139308bdd98db05902",
            "73739a4ba97f4885bb885784c48ab879",
            "bc0d425649a9413cb442e4b3e6c8e4a8",
            "94e9719834104d6382977e1dfca85dfd",
            "3ede26ea49694c409982f506687b7127",
            "da3f103fbfc9499095efe4210dc6dd6a",
            "7c88b69aa0e640a793f6ccb0b534b834",
            "7113a6b457174bca914916b19c43758e"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/16 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ff967abf058b4770b12ccd5f68851ffe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d6506b95c0424f308fc8dab31f1c6a72"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b4f5c93141a84d5e988fafd847579de3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['read', '##ability', 'is', 'complete']\n",
            "[3191, 8010, 2003, 3143]\n"
          ]
        }
      ],
      "source": [
        "tokenized_dataset = get_tokenized_data(train_valid_test_dataset,preprocess_function)\n",
        "\n",
        "tokens = tokenizer.tokenize(tokenized_dataset['train'][321]['tokens'])\n",
        "print(tokens)\n",
        "ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "print(ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "FAJS5aSnT4EO"
      },
      "outputs": [],
      "source": [
        "inputs = tokenizer(tokenized_dataset['train'][321]['tokens'])\n",
        "tokens = tokenizer.convert_ids_to_tokens(inputs['input_ids'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_t-HYs57T4EQ"
      },
      "source": [
        "As before, we can do the same via a Trainer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "T6f1AvYsT4ER",
        "outputId": "1c3abb41-cb20-4c4c-89da-2c8a01eb7275",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333\n",
            "Model config DistilBertConfig {\n",
            "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
            "  \"activation\": \"gelu\",\n",
            "  \"architectures\": [\n",
            "    \"DistilBertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"dim\": 768,\n",
            "  \"dropout\": 0.1,\n",
            "  \"hidden_dim\": 3072,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\",\n",
            "    \"4\": \"LABEL_4\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3,\n",
            "    \"LABEL_4\": 4\n",
            "  },\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"distilbert\",\n",
            "  \"n_heads\": 12,\n",
            "  \"n_layers\": 6,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"qa_dropout\": 0.1,\n",
            "  \"seq_classif_dropout\": 0.2,\n",
            "  \"sinusoidal_pos_embds\": false,\n",
            "  \"tie_weights_\": true,\n",
            "  \"transformers_version\": \"4.19.2\",\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.bias', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_projector.weight', 'vocab_layer_norm.weight']\n",
            "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'pre_classifier.bias', 'classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DistilBertForSequenceClassification(\n",
              "  (distilbert): DistilBertModel(\n",
              "    (embeddings): Embeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (transformer): Transformer(\n",
              "      (layer): ModuleList(\n",
              "        (0): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (activation): GELUActivation()\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (1): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (activation): GELUActivation()\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (2): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (activation): GELUActivation()\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (3): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (activation): GELUActivation()\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (4): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (activation): GELUActivation()\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (5): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (activation): GELUActivation()\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
              "  (dropout): Dropout(p=0.2, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "from transformers import DataCollatorWithPadding\n",
        "from datasets import load_metric\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "model = get_model(model_name)\n",
        "model.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "B4GGGRcpT4ER",
        "outputId": "58145e29-2310-4b7b-c197-5a2fe0e67ede",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
          ]
        }
      ],
      "source": [
        "training_args = get_trainingArgs()\n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "trainer = get_trainer(model,training_args,tokenized_dataset,tokenizer,data_collator,compute_metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "CubWwGyUT4ER",
        "outputId": "e2772666-9157-42d3-f519-e5b19381efe3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the training set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: tokens. If tokens are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 15068\n",
            "  Num Epochs = 10\n",
            "  Instantaneous batch size per device = 16\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 9420\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='9420' max='9420' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [9420/9420 13:35, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.120500</td>\n",
              "      <td>1.018119</td>\n",
              "      <td>0.579450</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.832700</td>\n",
              "      <td>1.030167</td>\n",
              "      <td>0.579450</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.677700</td>\n",
              "      <td>1.103121</td>\n",
              "      <td>0.572282</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.573900</td>\n",
              "      <td>1.211983</td>\n",
              "      <td>0.563919</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.499700</td>\n",
              "      <td>1.380552</td>\n",
              "      <td>0.557945</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.421200</td>\n",
              "      <td>1.429933</td>\n",
              "      <td>0.555556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.379700</td>\n",
              "      <td>1.573027</td>\n",
              "      <td>0.551971</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.347700</td>\n",
              "      <td>1.716951</td>\n",
              "      <td>0.549582</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.296400</td>\n",
              "      <td>1.788908</td>\n",
              "      <td>0.544803</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.268700</td>\n",
              "      <td>1.850411</td>\n",
              "      <td>0.547192</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: tokens. If tokens are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 837\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to ./results/checkpoint-942\n",
            "Configuration saved in ./results/checkpoint-942/config.json\n",
            "Model weights saved in ./results/checkpoint-942/pytorch_model.bin\n",
            "tokenizer config file saved in ./results/checkpoint-942/tokenizer_config.json\n",
            "Special tokens file saved in ./results/checkpoint-942/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: tokens. If tokens are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 837\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to ./results/checkpoint-1884\n",
            "Configuration saved in ./results/checkpoint-1884/config.json\n",
            "Model weights saved in ./results/checkpoint-1884/pytorch_model.bin\n",
            "tokenizer config file saved in ./results/checkpoint-1884/tokenizer_config.json\n",
            "Special tokens file saved in ./results/checkpoint-1884/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: tokens. If tokens are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 837\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to ./results/checkpoint-2826\n",
            "Configuration saved in ./results/checkpoint-2826/config.json\n",
            "Model weights saved in ./results/checkpoint-2826/pytorch_model.bin\n",
            "tokenizer config file saved in ./results/checkpoint-2826/tokenizer_config.json\n",
            "Special tokens file saved in ./results/checkpoint-2826/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: tokens. If tokens are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 837\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to ./results/checkpoint-3768\n",
            "Configuration saved in ./results/checkpoint-3768/config.json\n",
            "Model weights saved in ./results/checkpoint-3768/pytorch_model.bin\n",
            "tokenizer config file saved in ./results/checkpoint-3768/tokenizer_config.json\n",
            "Special tokens file saved in ./results/checkpoint-3768/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: tokens. If tokens are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 837\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to ./results/checkpoint-4710\n",
            "Configuration saved in ./results/checkpoint-4710/config.json\n",
            "Model weights saved in ./results/checkpoint-4710/pytorch_model.bin\n",
            "tokenizer config file saved in ./results/checkpoint-4710/tokenizer_config.json\n",
            "Special tokens file saved in ./results/checkpoint-4710/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: tokens. If tokens are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 837\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to ./results/checkpoint-5652\n",
            "Configuration saved in ./results/checkpoint-5652/config.json\n",
            "Model weights saved in ./results/checkpoint-5652/pytorch_model.bin\n",
            "tokenizer config file saved in ./results/checkpoint-5652/tokenizer_config.json\n",
            "Special tokens file saved in ./results/checkpoint-5652/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: tokens. If tokens are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 837\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to ./results/checkpoint-6594\n",
            "Configuration saved in ./results/checkpoint-6594/config.json\n",
            "Model weights saved in ./results/checkpoint-6594/pytorch_model.bin\n",
            "tokenizer config file saved in ./results/checkpoint-6594/tokenizer_config.json\n",
            "Special tokens file saved in ./results/checkpoint-6594/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: tokens. If tokens are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 837\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to ./results/checkpoint-7536\n",
            "Configuration saved in ./results/checkpoint-7536/config.json\n",
            "Model weights saved in ./results/checkpoint-7536/pytorch_model.bin\n",
            "tokenizer config file saved in ./results/checkpoint-7536/tokenizer_config.json\n",
            "Special tokens file saved in ./results/checkpoint-7536/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: tokens. If tokens are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 837\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to ./results/checkpoint-8478\n",
            "Configuration saved in ./results/checkpoint-8478/config.json\n",
            "Model weights saved in ./results/checkpoint-8478/pytorch_model.bin\n",
            "tokenizer config file saved in ./results/checkpoint-8478/tokenizer_config.json\n",
            "Special tokens file saved in ./results/checkpoint-8478/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: tokens. If tokens are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 837\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to ./results/checkpoint-9420\n",
            "Configuration saved in ./results/checkpoint-9420/config.json\n",
            "Model weights saved in ./results/checkpoint-9420/pytorch_model.bin\n",
            "tokenizer config file saved in ./results/checkpoint-9420/tokenizer_config.json\n",
            "Special tokens file saved in ./results/checkpoint-9420/special_tokens_map.json\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from ./results/checkpoint-942 (score: 1.0181193351745605).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=9420, training_loss=0.5340723365735096, metrics={'train_runtime': 816.165, 'train_samples_per_second': 184.62, 'train_steps_per_second': 11.542, 'total_flos': 1804236258808320.0, 'train_loss': 0.5340723365735096, 'epoch': 10.0})"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "17m9Thr1T4ER",
        "outputId": "180713ab-8d84-41e0-ad80-88bf2a86edd7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: tokens. If tokens are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 837\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='53' max='53' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [53/53 00:01]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'epoch': 10.0,\n",
              " 'eval_accuracy': 0.5794504181600956,\n",
              " 'eval_loss': 1.0181193351745605,\n",
              " 'eval_runtime': 1.2094,\n",
              " 'eval_samples_per_second': 692.063,\n",
              " 'eval_steps_per_second': 43.822}"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "trainer.evaluate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDdCQrHIT4ES"
      },
      "source": [
        "Note that we can still fine-tune the model with our training data, but the performance of the model is already quite good without any further training!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "TCXfF7JPT4ES",
        "outputId": "3214f5b6-91e0-4c8d-d72b-f6229ec1a5ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 925
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the test set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: tokens. If tokens are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Prediction *****\n",
            "  Num examples = 838\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='106' max='53' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [53/53 00:02]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PredictionOutput(predictions=array([[ 2.25409   , -2.1270857 ,  1.6971582 ,  0.07195746, -2.58587   ],\n",
              "       [ 1.8886373 , -2.1731105 ,  2.256175  , -0.07686514, -2.718885  ],\n",
              "       [ 0.9941894 , -0.44745404, -0.7372538 ,  2.5214257 , -2.5947573 ],\n",
              "       ...,\n",
              "       [ 1.7395928 ,  0.24864103, -1.8731446 , -0.8908734 ,  0.561481  ],\n",
              "       [ 2.2570903 , -0.2970044 , -1.1959621 ,  0.259524  , -1.4488842 ],\n",
              "       [ 1.7744514 ,  0.4688517 , -0.94809073,  0.6491876 , -2.1379273 ]],\n",
              "      dtype=float32), label_ids=array([0, 3, 3, 4, 0, 0, 0, 1, 3, 1, 0, 2, 3, 3, 0, 3, 1, 3, 3, 0, 0, 3,\n",
              "       1, 2, 0, 0, 3, 4, 0, 0, 3, 0, 0, 0, 2, 0, 3, 0, 2, 3, 0, 0, 3, 2,\n",
              "       4, 0, 3, 4, 0, 0, 3, 3, 1, 0, 2, 0, 3, 0, 4, 3, 2, 0, 2, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 1, 0, 0, 1, 0, 3, 3, 3, 3, 0, 0, 3,\n",
              "       0, 0, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 3, 3, 0, 3, 0, 0, 2,\n",
              "       0, 2, 3, 1, 0, 3, 0, 0, 0, 4, 3, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
              "       0, 0, 0, 2, 2, 1, 2, 0, 3, 0, 0, 2, 0, 3, 2, 0, 0, 1, 2, 2, 0, 2,\n",
              "       3, 0, 0, 1, 2, 0, 3, 1, 0, 3, 2, 3, 0, 0, 0, 0, 3, 0, 2, 3, 2, 2,\n",
              "       4, 4, 0, 2, 3, 0, 0, 0, 3, 2, 4, 0, 0, 0, 2, 1, 0, 0, 2, 0, 4, 0,\n",
              "       3, 2, 3, 2, 3, 0, 0, 0, 2, 0, 3, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 1, 3, 2, 0, 3, 3, 2, 3, 0, 0, 0, 0, 2, 0, 0, 3, 2, 3, 0, 0, 0,\n",
              "       2, 0, 3, 2, 3, 3, 2, 1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 1, 0, 0, 0, 0,\n",
              "       3, 2, 1, 3, 3, 3, 3, 1, 0, 4, 3, 0, 2, 2, 3, 1, 0, 3, 3, 0, 0, 0,\n",
              "       0, 0, 3, 2, 3, 1, 0, 2, 3, 2, 0, 3, 0, 3, 3, 3, 2, 3, 0, 0, 0, 1,\n",
              "       2, 1, 3, 2, 0, 1, 3, 0, 2, 0, 0, 3, 0, 3, 2, 2, 2, 0, 3, 0, 1, 2,\n",
              "       3, 2, 0, 3, 2, 3, 2, 0, 0, 2, 0, 1, 4, 3, 0, 2, 0, 1, 0, 2, 0, 0,\n",
              "       2, 2, 0, 1, 2, 1, 3, 2, 3, 0, 0, 2, 0, 0, 2, 0, 0, 4, 0, 3, 0, 0,\n",
              "       0, 3, 2, 0, 0, 0, 0, 0, 3, 2, 2, 0, 2, 2, 0, 3, 3, 3, 2, 3, 0, 0,\n",
              "       3, 0, 3, 3, 0, 3, 3, 3, 3, 0, 0, 2, 0, 0, 3, 3, 0, 0, 0, 3, 3, 0,\n",
              "       0, 2, 0, 3, 0, 0, 0, 3, 0, 3, 0, 0, 3, 3, 3, 3, 0, 0, 0, 2, 0, 3,\n",
              "       3, 1, 3, 0, 0, 3, 1, 0, 0, 3, 3, 3, 2, 0, 0, 0, 3, 0, 0, 2, 4, 3,\n",
              "       0, 0, 2, 0, 1, 2, 3, 0, 3, 0, 3, 0, 0, 0, 3, 2, 1, 2, 0, 0, 3, 2,\n",
              "       0, 1, 3, 3, 0, 0, 0, 3, 0, 3, 3, 0, 1, 3, 0, 0, 3, 0, 0, 0, 0, 4,\n",
              "       3, 0, 0, 0, 2, 0, 3, 0, 0, 1, 0, 0, 0, 0, 0, 0, 3, 0, 2, 0, 2, 0,\n",
              "       2, 0, 0, 0, 0, 3, 0, 0, 0, 3, 1, 0, 0, 0, 4, 3, 4, 0, 2, 0, 0, 1,\n",
              "       0, 3, 4, 3, 3, 2, 3, 2, 0, 0, 3, 0, 3, 3, 3, 3, 0, 3, 0, 3, 1, 0,\n",
              "       3, 0, 0, 2, 0, 0, 3, 0, 0, 0, 3, 3, 0, 0, 2, 0, 0, 0, 2, 0, 3, 0,\n",
              "       0, 2, 0, 2, 1, 0, 3, 0, 3, 2, 3, 2, 0, 2, 4, 3, 0, 0, 0, 0, 0, 3,\n",
              "       4, 1, 0, 2, 0, 3, 2, 3, 2, 2, 2, 3, 3, 3, 0, 4, 0, 1, 0, 0, 2, 0,\n",
              "       3, 0, 0, 2, 0, 2, 1, 2, 0, 1, 0, 0, 0, 0, 3, 0, 3, 0, 3, 0, 2, 0,\n",
              "       0, 4, 2, 3, 0, 0, 3, 3, 0, 0, 0, 3, 0, 0, 3, 2, 2, 3, 0, 1, 0, 0,\n",
              "       0, 0, 0, 2, 0, 3, 3, 0, 3, 0, 4, 2, 3, 2, 0, 3, 3, 2, 3, 0, 1, 0,\n",
              "       1, 0, 3, 3, 0, 2, 0, 1, 2, 0, 3, 1, 3, 2, 4, 2, 0, 2, 0, 4, 0, 3,\n",
              "       0, 0, 0, 4, 0, 2, 0, 2, 0, 2, 4, 2, 0, 0, 2, 0, 0, 0, 0, 3, 2, 2,\n",
              "       3, 3, 0, 3, 2, 3, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 3, 0, 2, 0, 1, 1,\n",
              "       0, 3, 3, 3, 0, 0, 0, 1, 0, 3, 0, 0, 2, 0, 3, 4, 2, 3, 1, 0, 2, 1,\n",
              "       3, 3, 0, 0, 4, 3, 0, 0, 2, 2, 2, 3, 3, 0, 0, 0, 1, 2, 0, 2, 0, 0,\n",
              "       0, 2, 2, 3, 2, 2, 0, 0, 2, 0, 0, 1, 0, 3, 3, 0, 2, 2, 3, 0, 0, 0,\n",
              "       0, 3]), metrics={'test_loss': 0.9717978239059448, 'test_accuracy': 0.5966587112171837, 'test_runtime': 1.2193, 'test_samples_per_second': 687.282, 'test_steps_per_second': 43.468})"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "trainer.predict(test_dataset=tokenized_dataset[\"test\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "UnTWi3t-T4ES",
        "outputId": "a16018c8-c02d-41b9-a137-9bc80b671969",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to ./results\n",
            "Configuration saved in ./results/config.json\n",
            "Model weights saved in ./results/pytorch_model.bin\n",
            "tokenizer config file saved in ./results/tokenizer_config.json\n",
            "Special tokens file saved in ./results/special_tokens_map.json\n"
          ]
        }
      ],
      "source": [
        "trainer.save_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "AqTM8SKzT4ES",
        "outputId": "67e348ed-4378-48d9-b03a-aa3438189489",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Didn't find file ./results/added_tokens.json. We won't load it.\n",
            "loading file ./results/vocab.txt\n",
            "loading file ./results/tokenizer.json\n",
            "loading file None\n",
            "loading file ./results/special_tokens_map.json\n",
            "loading file ./results/tokenizer_config.json\n",
            "loading configuration file ./results/config.json\n",
            "Model config DistilBertConfig {\n",
            "  \"_name_or_path\": \"./results\",\n",
            "  \"activation\": \"gelu\",\n",
            "  \"architectures\": [\n",
            "    \"DistilBertForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"dim\": 768,\n",
            "  \"dropout\": 0.1,\n",
            "  \"hidden_dim\": 3072,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\",\n",
            "    \"4\": \"LABEL_4\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3,\n",
            "    \"LABEL_4\": 4\n",
            "  },\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"distilbert\",\n",
            "  \"n_heads\": 12,\n",
            "  \"n_layers\": 6,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"problem_type\": \"single_label_classification\",\n",
            "  \"qa_dropout\": 0.1,\n",
            "  \"seq_classif_dropout\": 0.2,\n",
            "  \"sinusoidal_pos_embds\": false,\n",
            "  \"tie_weights_\": true,\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.19.2\",\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading weights file ./results/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
            "\n",
            "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at ./results.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "tokenizer2 = AutoTokenizer.from_pretrained(\"./results\")\n",
        "model2 = AutoModelForSequenceClassification.from_pretrained(\"./results\", num_labels=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "Rxr4z8BUT4ES"
      },
      "outputs": [],
      "source": [
        "from transformers import TextClassificationPipeline\n",
        "\n",
        "pipe = TextClassificationPipeline(model=model2, tokenizer=tokenizer2) #, return_all_scores=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "yrfwaL3LT4ES",
        "outputId": "b7560448-d340-407c-d64a-ce126dbb4311",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': tensor([[ 101, 1045, 5136, 2008, 2023, 2465, 2003, 2307,  102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
            "SequenceClassifierOutput(loss=None, logits=tensor([[ 1.6240,  1.5464, -1.6092, -0.5582, -0.8779]],\n",
            "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Value\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "inputs = \"I consider that this class is great\"\n",
        "\n",
        "# tokenize inputs\n",
        "tokenized_inputs = tokenizer2(inputs, return_tensors=\"pt\")\n",
        "print(tokenized_inputs)\n",
        "\n",
        "# obtain model outputs\n",
        "outputs = model2(**tokenized_inputs)\n",
        "print(outputs)\n",
        "\n",
        "# get the most likely label\n",
        "labels = ['Value', 'Value(+)', 'Value(-)', 'Fact', 'Policy']\n",
        "prediction = torch.argmax(outputs.logits)\n",
        "print(labels[prediction])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kA58qDC-T4ET"
      },
      "source": [
        "#### Testing for other models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "FuiW5QefT4ET",
        "outputId": "a5893284-83cc-4397-98e4-788faa847b42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
            "loading configuration file https://huggingface.co/YituTech/conv-bert-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/7651fc6ae3906f28c62923bc7c76b0436327540c1ebb62a60b454ec79e102dd1.2a398d65585c12446cf5e632a1839e1754dc16cbbf6b87ccf28ba24c8536394e\n",
            "Model config ConvBertConfig {\n",
            "  \"_name_or_path\": \"YituTech/conv-bert-base\",\n",
            "  \"architectures\": [\n",
            "    \"ConvBertModel\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"conv_kernel_size\": 9,\n",
            "  \"embedding_size\": 768,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"head_ratio\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"convbert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_groups\": 1,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.19.2\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading file https://huggingface.co/YituTech/conv-bert-base/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/75608c7373c277fa55de32e1bd71af40f547910ef3a49ed431d3a9fb9b4f5c8c.16ff552dabca3af1d1d07bc63a184047eb39f686be4a6738ba0167c6b1bb0b84\n",
            "loading file https://huggingface.co/YituTech/conv-bert-base/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/YituTech/conv-bert-base/resolve/main/special_tokens_map.json from cache at None\n",
            "loading file https://huggingface.co/YituTech/conv-bert-base/resolve/main/tokenizer_config.json from cache at None\n",
            "loading configuration file https://huggingface.co/YituTech/conv-bert-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/7651fc6ae3906f28c62923bc7c76b0436327540c1ebb62a60b454ec79e102dd1.2a398d65585c12446cf5e632a1839e1754dc16cbbf6b87ccf28ba24c8536394e\n",
            "Model config ConvBertConfig {\n",
            "  \"_name_or_path\": \"YituTech/conv-bert-base\",\n",
            "  \"architectures\": [\n",
            "    \"ConvBertModel\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"conv_kernel_size\": 9,\n",
            "  \"embedding_size\": 768,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"head_ratio\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"convbert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_groups\": 1,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.19.2\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading configuration file https://huggingface.co/YituTech/conv-bert-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/7651fc6ae3906f28c62923bc7c76b0436327540c1ebb62a60b454ec79e102dd1.2a398d65585c12446cf5e632a1839e1754dc16cbbf6b87ccf28ba24c8536394e\n",
            "Model config ConvBertConfig {\n",
            "  \"_name_or_path\": \"YituTech/conv-bert-base\",\n",
            "  \"architectures\": [\n",
            "    \"ConvBertModel\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"conv_kernel_size\": 9,\n",
            "  \"embedding_size\": 768,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"head_ratio\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"convbert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_groups\": 1,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.19.2\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading configuration file https://huggingface.co/YituTech/conv-bert-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/7651fc6ae3906f28c62923bc7c76b0436327540c1ebb62a60b454ec79e102dd1.2a398d65585c12446cf5e632a1839e1754dc16cbbf6b87ccf28ba24c8536394e\n",
            "Model config ConvBertConfig {\n",
            "  \"_name_or_path\": \"YituTech/conv-bert-base\",\n",
            "  \"architectures\": [\n",
            "    \"ConvBertModel\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"conv_kernel_size\": 9,\n",
            "  \"embedding_size\": 768,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"head_ratio\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\",\n",
            "    \"4\": \"LABEL_4\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3,\n",
            "    \"LABEL_4\": 4\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"convbert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_groups\": 1,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.19.2\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/YituTech/conv-bert-base/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/f71042767b7bb431c7632b9f245661cd34a5edaac1eaf25f3a9e78a73bb711b2.3ee89f2fd82df871ab2d6f643874ee269c534627432695a69f22271e9d077426\n",
            "All model checkpoint weights were used when initializing ConvBertForSequenceClassification.\n",
            "\n",
            "Some weights of ConvBertForSequenceClassification were not initialized from the model checkpoint at YituTech/conv-bert-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "The following columns in the training set don't have a corresponding argument in `ConvBertForSequenceClassification.forward` and have been ignored: tokens. If tokens are not expected by `ConvBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 15068\n",
            "  Num Epochs = 10\n",
            "  Instantaneous batch size per device = 16\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 9420\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='9420' max='9420' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [9420/9420 30:07, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.136800</td>\n",
              "      <td>0.999008</td>\n",
              "      <td>0.592593</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.799500</td>\n",
              "      <td>1.021791</td>\n",
              "      <td>0.583035</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.657800</td>\n",
              "      <td>1.096190</td>\n",
              "      <td>0.585424</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.549200</td>\n",
              "      <td>1.220061</td>\n",
              "      <td>0.574671</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.474700</td>\n",
              "      <td>1.385403</td>\n",
              "      <td>0.557945</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.404900</td>\n",
              "      <td>1.473258</td>\n",
              "      <td>0.565114</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.355300</td>\n",
              "      <td>1.677509</td>\n",
              "      <td>0.557945</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.331800</td>\n",
              "      <td>1.760551</td>\n",
              "      <td>0.554361</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.278900</td>\n",
              "      <td>1.876332</td>\n",
              "      <td>0.562724</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.247000</td>\n",
              "      <td>1.953640</td>\n",
              "      <td>0.556750</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the evaluation set don't have a corresponding argument in `ConvBertForSequenceClassification.forward` and have been ignored: tokens. If tokens are not expected by `ConvBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 837\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to ./results/checkpoint-942\n",
            "Configuration saved in ./results/checkpoint-942/config.json\n",
            "Model weights saved in ./results/checkpoint-942/pytorch_model.bin\n",
            "tokenizer config file saved in ./results/checkpoint-942/tokenizer_config.json\n",
            "Special tokens file saved in ./results/checkpoint-942/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `ConvBertForSequenceClassification.forward` and have been ignored: tokens. If tokens are not expected by `ConvBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 837\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to ./results/checkpoint-1884\n",
            "Configuration saved in ./results/checkpoint-1884/config.json\n",
            "Model weights saved in ./results/checkpoint-1884/pytorch_model.bin\n",
            "tokenizer config file saved in ./results/checkpoint-1884/tokenizer_config.json\n",
            "Special tokens file saved in ./results/checkpoint-1884/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `ConvBertForSequenceClassification.forward` and have been ignored: tokens. If tokens are not expected by `ConvBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 837\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to ./results/checkpoint-2826\n",
            "Configuration saved in ./results/checkpoint-2826/config.json\n",
            "Model weights saved in ./results/checkpoint-2826/pytorch_model.bin\n",
            "tokenizer config file saved in ./results/checkpoint-2826/tokenizer_config.json\n",
            "Special tokens file saved in ./results/checkpoint-2826/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `ConvBertForSequenceClassification.forward` and have been ignored: tokens. If tokens are not expected by `ConvBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 837\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to ./results/checkpoint-3768\n",
            "Configuration saved in ./results/checkpoint-3768/config.json\n",
            "Model weights saved in ./results/checkpoint-3768/pytorch_model.bin\n",
            "tokenizer config file saved in ./results/checkpoint-3768/tokenizer_config.json\n",
            "Special tokens file saved in ./results/checkpoint-3768/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `ConvBertForSequenceClassification.forward` and have been ignored: tokens. If tokens are not expected by `ConvBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 837\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to ./results/checkpoint-4710\n",
            "Configuration saved in ./results/checkpoint-4710/config.json\n",
            "Model weights saved in ./results/checkpoint-4710/pytorch_model.bin\n",
            "tokenizer config file saved in ./results/checkpoint-4710/tokenizer_config.json\n",
            "Special tokens file saved in ./results/checkpoint-4710/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `ConvBertForSequenceClassification.forward` and have been ignored: tokens. If tokens are not expected by `ConvBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 837\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to ./results/checkpoint-5652\n",
            "Configuration saved in ./results/checkpoint-5652/config.json\n",
            "Model weights saved in ./results/checkpoint-5652/pytorch_model.bin\n",
            "tokenizer config file saved in ./results/checkpoint-5652/tokenizer_config.json\n",
            "Special tokens file saved in ./results/checkpoint-5652/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `ConvBertForSequenceClassification.forward` and have been ignored: tokens. If tokens are not expected by `ConvBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 837\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to ./results/checkpoint-6594\n",
            "Configuration saved in ./results/checkpoint-6594/config.json\n",
            "Model weights saved in ./results/checkpoint-6594/pytorch_model.bin\n",
            "tokenizer config file saved in ./results/checkpoint-6594/tokenizer_config.json\n",
            "Special tokens file saved in ./results/checkpoint-6594/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `ConvBertForSequenceClassification.forward` and have been ignored: tokens. If tokens are not expected by `ConvBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 837\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to ./results/checkpoint-7536\n",
            "Configuration saved in ./results/checkpoint-7536/config.json\n",
            "Model weights saved in ./results/checkpoint-7536/pytorch_model.bin\n",
            "tokenizer config file saved in ./results/checkpoint-7536/tokenizer_config.json\n",
            "Special tokens file saved in ./results/checkpoint-7536/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `ConvBertForSequenceClassification.forward` and have been ignored: tokens. If tokens are not expected by `ConvBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 837\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to ./results/checkpoint-8478\n",
            "Configuration saved in ./results/checkpoint-8478/config.json\n",
            "Model weights saved in ./results/checkpoint-8478/pytorch_model.bin\n",
            "tokenizer config file saved in ./results/checkpoint-8478/tokenizer_config.json\n",
            "Special tokens file saved in ./results/checkpoint-8478/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `ConvBertForSequenceClassification.forward` and have been ignored: tokens. If tokens are not expected by `ConvBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 837\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to ./results/checkpoint-9420\n",
            "Configuration saved in ./results/checkpoint-9420/config.json\n",
            "Model weights saved in ./results/checkpoint-9420/pytorch_model.bin\n",
            "tokenizer config file saved in ./results/checkpoint-9420/tokenizer_config.json\n",
            "Special tokens file saved in ./results/checkpoint-9420/special_tokens_map.json\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from ./results/checkpoint-942 (score: 0.9990077018737793).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=9420, training_loss=0.5133514671568657, metrics={'train_runtime': 1808.32, 'train_samples_per_second': 83.326, 'train_steps_per_second': 5.209, 'total_flos': 3449186822939136.0, 'train_loss': 0.5133514671568657, 'epoch': 10.0})"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "model_name = \"YituTech/conv-bert-base\"\n",
        "tokenizer = get_tokenizer(model_name)\n",
        "model = get_model(model_name)\n",
        "\n",
        "training_args = get_trainingArgs()\n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "trainer = get_trainer(model,training_args,tokenized_dataset,tokenizer,data_collator,compute_metrics)\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "VsXovM6DT4ET",
        "outputId": "b04bdc77-c256-4373-ce10-7006511e049b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the evaluation set don't have a corresponding argument in `ConvBertForSequenceClassification.forward` and have been ignored: tokens. If tokens are not expected by `ConvBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 837\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='53' max='53' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [53/53 00:02]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'epoch': 10.0,\n",
              " 'eval_accuracy': 0.5925925925925926,\n",
              " 'eval_loss': 0.9990077018737793,\n",
              " 'eval_runtime': 2.5681,\n",
              " 'eval_samples_per_second': 325.922,\n",
              " 'eval_steps_per_second': 20.638}"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "trainer.evaluate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "TSFtV6WST4ET",
        "outputId": "aa595006-ac7e-4d90-8fdd-4c58b71d7352",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 925
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the test set don't have a corresponding argument in `ConvBertForSequenceClassification.forward` and have been ignored: tokens. If tokens are not expected by `ConvBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Prediction *****\n",
            "  Num examples = 838\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='106' max='53' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [53/53 00:05]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PredictionOutput(predictions=array([[ 2.6817122 , -1.2507981 ,  0.5966191 ,  0.5713838 , -2.0820625 ],\n",
              "       [ 1.0768876 , -1.9822626 ,  2.4556732 , -0.0561501 , -1.8347462 ],\n",
              "       [ 1.0974739 , -0.6719573 , -0.4694883 ,  3.0028603 , -2.6525857 ],\n",
              "       ...,\n",
              "       [ 1.5312034 , -0.7468105 , -1.3785452 , -1.0388649 ,  1.5676636 ],\n",
              "       [ 2.6586072 , -0.15121448, -0.71098953,  0.49706525, -1.424864  ],\n",
              "       [ 1.9450687 ,  0.81677234, -1.168717  ,  1.3485212 , -2.1756992 ]],\n",
              "      dtype=float32), label_ids=array([0, 3, 3, 4, 0, 0, 0, 1, 3, 1, 0, 2, 3, 3, 0, 3, 1, 3, 3, 0, 0, 3,\n",
              "       1, 2, 0, 0, 3, 4, 0, 0, 3, 0, 0, 0, 2, 0, 3, 0, 2, 3, 0, 0, 3, 2,\n",
              "       4, 0, 3, 4, 0, 0, 3, 3, 1, 0, 2, 0, 3, 0, 4, 3, 2, 0, 2, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 1, 0, 0, 1, 0, 3, 3, 3, 3, 0, 0, 3,\n",
              "       0, 0, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 3, 3, 0, 3, 0, 0, 2,\n",
              "       0, 2, 3, 1, 0, 3, 0, 0, 0, 4, 3, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
              "       0, 0, 0, 2, 2, 1, 2, 0, 3, 0, 0, 2, 0, 3, 2, 0, 0, 1, 2, 2, 0, 2,\n",
              "       3, 0, 0, 1, 2, 0, 3, 1, 0, 3, 2, 3, 0, 0, 0, 0, 3, 0, 2, 3, 2, 2,\n",
              "       4, 4, 0, 2, 3, 0, 0, 0, 3, 2, 4, 0, 0, 0, 2, 1, 0, 0, 2, 0, 4, 0,\n",
              "       3, 2, 3, 2, 3, 0, 0, 0, 2, 0, 3, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 1, 3, 2, 0, 3, 3, 2, 3, 0, 0, 0, 0, 2, 0, 0, 3, 2, 3, 0, 0, 0,\n",
              "       2, 0, 3, 2, 3, 3, 2, 1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 1, 0, 0, 0, 0,\n",
              "       3, 2, 1, 3, 3, 3, 3, 1, 0, 4, 3, 0, 2, 2, 3, 1, 0, 3, 3, 0, 0, 0,\n",
              "       0, 0, 3, 2, 3, 1, 0, 2, 3, 2, 0, 3, 0, 3, 3, 3, 2, 3, 0, 0, 0, 1,\n",
              "       2, 1, 3, 2, 0, 1, 3, 0, 2, 0, 0, 3, 0, 3, 2, 2, 2, 0, 3, 0, 1, 2,\n",
              "       3, 2, 0, 3, 2, 3, 2, 0, 0, 2, 0, 1, 4, 3, 0, 2, 0, 1, 0, 2, 0, 0,\n",
              "       2, 2, 0, 1, 2, 1, 3, 2, 3, 0, 0, 2, 0, 0, 2, 0, 0, 4, 0, 3, 0, 0,\n",
              "       0, 3, 2, 0, 0, 0, 0, 0, 3, 2, 2, 0, 2, 2, 0, 3, 3, 3, 2, 3, 0, 0,\n",
              "       3, 0, 3, 3, 0, 3, 3, 3, 3, 0, 0, 2, 0, 0, 3, 3, 0, 0, 0, 3, 3, 0,\n",
              "       0, 2, 0, 3, 0, 0, 0, 3, 0, 3, 0, 0, 3, 3, 3, 3, 0, 0, 0, 2, 0, 3,\n",
              "       3, 1, 3, 0, 0, 3, 1, 0, 0, 3, 3, 3, 2, 0, 0, 0, 3, 0, 0, 2, 4, 3,\n",
              "       0, 0, 2, 0, 1, 2, 3, 0, 3, 0, 3, 0, 0, 0, 3, 2, 1, 2, 0, 0, 3, 2,\n",
              "       0, 1, 3, 3, 0, 0, 0, 3, 0, 3, 3, 0, 1, 3, 0, 0, 3, 0, 0, 0, 0, 4,\n",
              "       3, 0, 0, 0, 2, 0, 3, 0, 0, 1, 0, 0, 0, 0, 0, 0, 3, 0, 2, 0, 2, 0,\n",
              "       2, 0, 0, 0, 0, 3, 0, 0, 0, 3, 1, 0, 0, 0, 4, 3, 4, 0, 2, 0, 0, 1,\n",
              "       0, 3, 4, 3, 3, 2, 3, 2, 0, 0, 3, 0, 3, 3, 3, 3, 0, 3, 0, 3, 1, 0,\n",
              "       3, 0, 0, 2, 0, 0, 3, 0, 0, 0, 3, 3, 0, 0, 2, 0, 0, 0, 2, 0, 3, 0,\n",
              "       0, 2, 0, 2, 1, 0, 3, 0, 3, 2, 3, 2, 0, 2, 4, 3, 0, 0, 0, 0, 0, 3,\n",
              "       4, 1, 0, 2, 0, 3, 2, 3, 2, 2, 2, 3, 3, 3, 0, 4, 0, 1, 0, 0, 2, 0,\n",
              "       3, 0, 0, 2, 0, 2, 1, 2, 0, 1, 0, 0, 0, 0, 3, 0, 3, 0, 3, 0, 2, 0,\n",
              "       0, 4, 2, 3, 0, 0, 3, 3, 0, 0, 0, 3, 0, 0, 3, 2, 2, 3, 0, 1, 0, 0,\n",
              "       0, 0, 0, 2, 0, 3, 3, 0, 3, 0, 4, 2, 3, 2, 0, 3, 3, 2, 3, 0, 1, 0,\n",
              "       1, 0, 3, 3, 0, 2, 0, 1, 2, 0, 3, 1, 3, 2, 4, 2, 0, 2, 0, 4, 0, 3,\n",
              "       0, 0, 0, 4, 0, 2, 0, 2, 0, 2, 4, 2, 0, 0, 2, 0, 0, 0, 0, 3, 2, 2,\n",
              "       3, 3, 0, 3, 2, 3, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 3, 0, 2, 0, 1, 1,\n",
              "       0, 3, 3, 3, 0, 0, 0, 1, 0, 3, 0, 0, 2, 0, 3, 4, 2, 3, 1, 0, 2, 1,\n",
              "       3, 3, 0, 0, 4, 3, 0, 0, 2, 2, 2, 3, 3, 0, 0, 0, 1, 2, 0, 2, 0, 0,\n",
              "       0, 2, 2, 3, 2, 2, 0, 0, 2, 0, 0, 1, 0, 3, 3, 0, 2, 2, 3, 0, 0, 0,\n",
              "       0, 3]), metrics={'test_loss': 0.9420706629753113, 'test_accuracy': 0.594272076372315, 'test_runtime': 2.5456, 'test_samples_per_second': 329.19, 'test_steps_per_second': 20.82})"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "trainer.predict(test_dataset=tokenized_dataset[\"test\"])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save_model()"
      ],
      "metadata": {
        "id": "4GtnwLPFiZwF",
        "outputId": "a1a2d481-d17a-4578-f24a-c0c92519dea6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to ./results\n",
            "Configuration saved in ./results/config.json\n",
            "Model weights saved in ./results/pytorch_model.bin\n",
            "tokenizer config file saved in ./results/tokenizer_config.json\n",
            "Special tokens file saved in ./results/special_tokens_map.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "B99nYXZiT4ET",
        "outputId": "7031aca9-a5cc-4d70-832f-d80ca3b78f9c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Didn't find file ./results/added_tokens.json. We won't load it.\n",
            "loading file ./results/vocab.txt\n",
            "loading file None\n",
            "loading file ./results/special_tokens_map.json\n",
            "loading file ./results/tokenizer_config.json\n",
            "loading configuration file ./results/config.json\n",
            "Model config ConvBertConfig {\n",
            "  \"_name_or_path\": \"./results\",\n",
            "  \"architectures\": [\n",
            "    \"ConvBertForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"conv_kernel_size\": 9,\n",
            "  \"embedding_size\": 768,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"head_ratio\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\",\n",
            "    \"4\": \"LABEL_4\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3,\n",
            "    \"LABEL_4\": 4\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"convbert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_groups\": 1,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"problem_type\": \"single_label_classification\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.19.2\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading weights file ./results/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing ConvBertForSequenceClassification.\n",
            "\n",
            "All the weights of ConvBertForSequenceClassification were initialized from the model checkpoint at ./results.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use ConvBertForSequenceClassification for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': tensor([[ 101, 1045, 4632, 1504, 1519, 1961, 1499, 1803,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
            "SequenceClassifierOutput(loss=None, logits=tensor([[ 2.0991, -1.7663,  1.1772,  1.3581, -2.6614]],\n",
            "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "Value\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "tokenizer2 = AutoTokenizer.from_pretrained(\"./results\")\n",
        "model2 = AutoModelForSequenceClassification.from_pretrained(\"./results\", num_labels=5)\n",
        "\n",
        "from transformers import TextClassificationPipeline\n",
        "\n",
        "pipe = TextClassificationPipeline(model=model2, tokenizer=tokenizer2) #, return_all_scores=True)\n",
        "\n",
        "import torch\n",
        "\n",
        "inputs = \"I consider that this class is great\"\n",
        "\n",
        "# tokenize inputs\n",
        "tokenized_inputs = tokenizer2(inputs, return_tensors=\"pt\")\n",
        "print(tokenized_inputs)\n",
        "\n",
        "# obtain model outputs\n",
        "outputs = model2(**tokenized_inputs)\n",
        "print(outputs)\n",
        "\n",
        "# get the most likely label\n",
        "labels = ['Value', 'Value(+)', 'Value(-)', 'Fact', 'Policy']\n",
        "prediction = torch.argmax(outputs.logits)\n",
        "print(labels[prediction])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "transformers.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "36d4526adc5d47629ba603c5df46b243": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b306cfe93ab44128840561f1345c9016",
              "IPY_MODEL_0636bdff4a2043b4b954ee136bf86344",
              "IPY_MODEL_ecc0d68b548c4fe692e4d8d4e5bf807d"
            ],
            "layout": "IPY_MODEL_dbdb2753385042dbab50025456048ce2"
          }
        },
        "b306cfe93ab44128840561f1345c9016": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff67fc6cfb494896800482187befc142",
            "placeholder": "​",
            "style": "IPY_MODEL_31c4d4af07de446994419cdba2c1113d",
            "value": "100%"
          }
        },
        "0636bdff4a2043b4b954ee136bf86344": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_71d36b9847d54970a1a859d4ed2e883f",
            "max": 16,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3f3e695ec5594eb5bd87ca603b4fc6cb",
            "value": 16
          }
        },
        "ecc0d68b548c4fe692e4d8d4e5bf807d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9de20244084748f0be6277d17616e84c",
            "placeholder": "​",
            "style": "IPY_MODEL_a9a1d407a693407dabbe27ea6bda367e",
            "value": " 16/16 [00:02&lt;00:00, 10.11ba/s]"
          }
        },
        "dbdb2753385042dbab50025456048ce2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff67fc6cfb494896800482187befc142": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31c4d4af07de446994419cdba2c1113d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "71d36b9847d54970a1a859d4ed2e883f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f3e695ec5594eb5bd87ca603b4fc6cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9de20244084748f0be6277d17616e84c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9a1d407a693407dabbe27ea6bda367e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "96c812663c494400bcc34da831f50e78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3b051ac83599451ca7ebab4e4c7ba1cd",
              "IPY_MODEL_577af2d225f24d0f9bf5aada5cf6c853",
              "IPY_MODEL_c31d7ca0c82244b2a5addfdb6326c461"
            ],
            "layout": "IPY_MODEL_3baafd0d5d7641a7b089093400edae42"
          }
        },
        "3b051ac83599451ca7ebab4e4c7ba1cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_72ffbd33630a4378a65cb469ab5794b4",
            "placeholder": "​",
            "style": "IPY_MODEL_5d8ea16e81b64f8c95dc4ce4e314a936",
            "value": "100%"
          }
        },
        "577af2d225f24d0f9bf5aada5cf6c853": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e44e7ac28604b2fbc07528211da887d",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fff7eec9c01f4a23867fe3b9e95bac72",
            "value": 1
          }
        },
        "c31d7ca0c82244b2a5addfdb6326c461": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a75fa04969884cbb9a0c3f8594c29d93",
            "placeholder": "​",
            "style": "IPY_MODEL_ac8e7e9a61254c34973e204098f2c59a",
            "value": " 1/1 [00:00&lt;00:00,  8.88ba/s]"
          }
        },
        "3baafd0d5d7641a7b089093400edae42": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72ffbd33630a4378a65cb469ab5794b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d8ea16e81b64f8c95dc4ce4e314a936": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3e44e7ac28604b2fbc07528211da887d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fff7eec9c01f4a23867fe3b9e95bac72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a75fa04969884cbb9a0c3f8594c29d93": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac8e7e9a61254c34973e204098f2c59a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1391a8b8214e4dfd9847edbb6cb6f94e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_246560a14b4e4ee9a2bfbe13c68c44fa",
              "IPY_MODEL_9330bbbb325f431c80a9386d22a3415f",
              "IPY_MODEL_f1d084b7da674a9aabfb933f57c88176"
            ],
            "layout": "IPY_MODEL_42b2c21c8a754733bc370e4e3ec7b4b2"
          }
        },
        "246560a14b4e4ee9a2bfbe13c68c44fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fda6f3526ff0484cb76463e2d57f9a8e",
            "placeholder": "​",
            "style": "IPY_MODEL_600f7ec6343f4be18cd5b94cfc4581d5",
            "value": "100%"
          }
        },
        "9330bbbb325f431c80a9386d22a3415f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5abc87d016694764ad630d0afce5341d",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a6c64e87df524376a89a964a0a5e6aee",
            "value": 1
          }
        },
        "f1d084b7da674a9aabfb933f57c88176": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_400b7a93278349788eae044f406d4fac",
            "placeholder": "​",
            "style": "IPY_MODEL_0d5e48a7c6da424ba29ae2d81db3682a",
            "value": " 1/1 [00:00&lt;00:00, 10.00ba/s]"
          }
        },
        "42b2c21c8a754733bc370e4e3ec7b4b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fda6f3526ff0484cb76463e2d57f9a8e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "600f7ec6343f4be18cd5b94cfc4581d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5abc87d016694764ad630d0afce5341d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6c64e87df524376a89a964a0a5e6aee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "400b7a93278349788eae044f406d4fac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d5e48a7c6da424ba29ae2d81db3682a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8f873d4ed4be4e299f2dff361e42ae59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d8f6528300b4404cbb5c2013fb26a002",
              "IPY_MODEL_fbf41f25edb444948260358d0094367d",
              "IPY_MODEL_5e15d4927175477e8882ba2bf757b7ff"
            ],
            "layout": "IPY_MODEL_7ece68b733d1428d903119b954736ebc"
          }
        },
        "d8f6528300b4404cbb5c2013fb26a002": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_11d64f3e5d314f18ae2342bcedd5e238",
            "placeholder": "​",
            "style": "IPY_MODEL_68d830797b0a46b1813fae11f40df1ae",
            "value": "Downloading: 100%"
          }
        },
        "fbf41f25edb444948260358d0094367d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a9f2e554a534131b7b08db124f88c38",
            "max": 155,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_01a6932e788543b2982ebf707cc706f8",
            "value": 155
          }
        },
        "5e15d4927175477e8882ba2bf757b7ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_40c898b2d025458f9ae5503790ab9f14",
            "placeholder": "​",
            "style": "IPY_MODEL_d2522c9d2fd946c4920da1c3e3a07bde",
            "value": " 155/155 [00:00&lt;00:00, 4.51kB/s]"
          }
        },
        "7ece68b733d1428d903119b954736ebc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11d64f3e5d314f18ae2342bcedd5e238": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68d830797b0a46b1813fae11f40df1ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6a9f2e554a534131b7b08db124f88c38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01a6932e788543b2982ebf707cc706f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "40c898b2d025458f9ae5503790ab9f14": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2522c9d2fd946c4920da1c3e3a07bde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "15d1239ad0a244099a29349621dc5628": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7f5fd7e0aa3745318bef6c9060340db4",
              "IPY_MODEL_467eea54606144b9a2603c31ac821f9a",
              "IPY_MODEL_87624c2bec054913a3555acfcf5fdc62"
            ],
            "layout": "IPY_MODEL_3844a673b5dd4be99096c36b383b4c91"
          }
        },
        "7f5fd7e0aa3745318bef6c9060340db4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1552832df2ae41748171bd48bd972f54",
            "placeholder": "​",
            "style": "IPY_MODEL_ac482944bbd9433089a9c614f2fe13af",
            "value": "Downloading: 100%"
          }
        },
        "467eea54606144b9a2603c31ac821f9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4130da3f372b4a1481132c55846a0137",
            "max": 648,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_660d9f0d95da47cd9c73b31f2817b059",
            "value": 648
          }
        },
        "87624c2bec054913a3555acfcf5fdc62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03d8ad78f92441c09d914ce13b6b9b2f",
            "placeholder": "​",
            "style": "IPY_MODEL_661861efeb0c48dea14281d2d098fdfb",
            "value": " 648/648 [00:00&lt;00:00, 20.6kB/s]"
          }
        },
        "3844a673b5dd4be99096c36b383b4c91": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1552832df2ae41748171bd48bd972f54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac482944bbd9433089a9c614f2fe13af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4130da3f372b4a1481132c55846a0137": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "660d9f0d95da47cd9c73b31f2817b059": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "03d8ad78f92441c09d914ce13b6b9b2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "661861efeb0c48dea14281d2d098fdfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1a52b9ac88164fa1a6c0958d111b5df5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9d368e0f244e4961b35470f93ec1c3e0",
              "IPY_MODEL_82ce402f2c36491db0834776798d2c39",
              "IPY_MODEL_900a330866c24c94afa95afe47633316"
            ],
            "layout": "IPY_MODEL_04967cfae21144bfbd9a15cc0ee23652"
          }
        },
        "9d368e0f244e4961b35470f93ec1c3e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_afc5f8cd4b3c4f01811c7c95c1fb001b",
            "placeholder": "​",
            "style": "IPY_MODEL_40dfb5575a5a429fad2585907df0d8c7",
            "value": "Downloading: 100%"
          }
        },
        "82ce402f2c36491db0834776798d2c39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7dc56408d8a6407fa5c2088290900706",
            "max": 209528,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_60c7692b7f1a47ac89ca344ef009df48",
            "value": 209528
          }
        },
        "900a330866c24c94afa95afe47633316": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8befc173fda24be38c6929e825888e8b",
            "placeholder": "​",
            "style": "IPY_MODEL_d2d5ec624b9e42c69f8cc1eb3bca7997",
            "value": " 205k/205k [00:00&lt;00:00, 176kB/s]"
          }
        },
        "04967cfae21144bfbd9a15cc0ee23652": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "afc5f8cd4b3c4f01811c7c95c1fb001b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40dfb5575a5a429fad2585907df0d8c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7dc56408d8a6407fa5c2088290900706": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60c7692b7f1a47ac89ca344ef009df48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8befc173fda24be38c6929e825888e8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2d5ec624b9e42c69f8cc1eb3bca7997": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ceed78d1d09b49ea83aa90457b8290b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ad6dbaf62ce5402b8a2a17285316665e",
              "IPY_MODEL_be2b738159fd41ec9c69a711db8a7bb6",
              "IPY_MODEL_630d4d7334984f2186620868fbc682a0"
            ],
            "layout": "IPY_MODEL_a195560bc9d44e67a70aec6f9097f5a4"
          }
        },
        "ad6dbaf62ce5402b8a2a17285316665e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5fce26a2ab43462b9972d7da48ab406d",
            "placeholder": "​",
            "style": "IPY_MODEL_1b471337448c4f118823ec3109652186",
            "value": "Downloading: 100%"
          }
        },
        "be2b738159fd41ec9c69a711db8a7bb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7fe54986c3474c2bb79d75510785a6d6",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_aad94ba6acf2479b873d0f898acf4083",
            "value": 2
          }
        },
        "630d4d7334984f2186620868fbc682a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5606eecc3b5f40eaaf4e99087153e185",
            "placeholder": "​",
            "style": "IPY_MODEL_b7da6e09530d46a4a34d77f698724158",
            "value": " 2.00/2.00 [00:00&lt;00:00, 31.7B/s]"
          }
        },
        "a195560bc9d44e67a70aec6f9097f5a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5fce26a2ab43462b9972d7da48ab406d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b471337448c4f118823ec3109652186": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7fe54986c3474c2bb79d75510785a6d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aad94ba6acf2479b873d0f898acf4083": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5606eecc3b5f40eaaf4e99087153e185": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7da6e09530d46a4a34d77f698724158": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "afd9952998114ce19e96dba92b2a1343": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_43ed4ed1c4c04cf48b6b9733cf27bc5b",
              "IPY_MODEL_7d8b6ac5b3eb4e4caa3aa0095fa1c9a0",
              "IPY_MODEL_a1aa5ff8d011486f81e37e9c0f45e783"
            ],
            "layout": "IPY_MODEL_9e038e29162b4c3885c8bf737d73253c"
          }
        },
        "43ed4ed1c4c04cf48b6b9733cf27bc5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b29dee7aa02a4ddd929956559b34c132",
            "placeholder": "​",
            "style": "IPY_MODEL_3a64a0b392804f269c449f6b47205376",
            "value": "Downloading: 100%"
          }
        },
        "7d8b6ac5b3eb4e4caa3aa0095fa1c9a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec3d262681014415947f0530a74da919",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d0fa96a64c5541b08edea29a7737fd1a",
            "value": 112
          }
        },
        "a1aa5ff8d011486f81e37e9c0f45e783": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7a66d4927fc409dbcf031519abf02a0",
            "placeholder": "​",
            "style": "IPY_MODEL_8c180b9c52314cc883629033453b806e",
            "value": " 112/112 [00:00&lt;00:00, 3.73kB/s]"
          }
        },
        "9e038e29162b4c3885c8bf737d73253c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b29dee7aa02a4ddd929956559b34c132": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a64a0b392804f269c449f6b47205376": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ec3d262681014415947f0530a74da919": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0fa96a64c5541b08edea29a7737fd1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a7a66d4927fc409dbcf031519abf02a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c180b9c52314cc883629033453b806e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a1d9f7da46394d82b706516608aa40ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_04145ae3b39d446c9e452daedf10425f",
              "IPY_MODEL_462620b853be453a91df73f751a18481",
              "IPY_MODEL_4717a02dcc25487fa2d701334346de14"
            ],
            "layout": "IPY_MODEL_a2826375b76e445380679747595a4b4a"
          }
        },
        "04145ae3b39d446c9e452daedf10425f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0593c216a3be44ab87961835dd488358",
            "placeholder": "​",
            "style": "IPY_MODEL_5b749e529b4948999a7832bd8e8503b3",
            "value": "Downloading: 100%"
          }
        },
        "462620b853be453a91df73f751a18481": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce897a98d3c24d1988d5f4eed8ca94aa",
            "max": 1342014951,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a541e10f444b4b8298d74ddc5a1c0147",
            "value": 1342014951
          }
        },
        "4717a02dcc25487fa2d701334346de14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c955bf3510624995a4229794e71549e0",
            "placeholder": "​",
            "style": "IPY_MODEL_561abd6ac5374ccd8df59f0ad0d21743",
            "value": " 1.25G/1.25G [00:59&lt;00:00, 24.4MB/s]"
          }
        },
        "a2826375b76e445380679747595a4b4a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0593c216a3be44ab87961835dd488358": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b749e529b4948999a7832bd8e8503b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ce897a98d3c24d1988d5f4eed8ca94aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a541e10f444b4b8298d74ddc5a1c0147": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c955bf3510624995a4229794e71549e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "561abd6ac5374ccd8df59f0ad0d21743": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ff967abf058b4770b12ccd5f68851ffe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_96ddaeef13b146409ff3a9cdd914e1d2",
              "IPY_MODEL_9cbcc8cd2cd14eb1b9ae21402fd4c27d",
              "IPY_MODEL_bf51904065314de48222a4a3c9020c53"
            ],
            "layout": "IPY_MODEL_3557f09c6b81438595837a502bae39f1"
          }
        },
        "96ddaeef13b146409ff3a9cdd914e1d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ad7e3ae59b74c848fb5cee7eea29201",
            "placeholder": "​",
            "style": "IPY_MODEL_25f24252c96340f19559727cfb3de776",
            "value": "100%"
          }
        },
        "9cbcc8cd2cd14eb1b9ae21402fd4c27d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a990af301ed4daaa03937b94f56ca12",
            "max": 16,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1fc46561e9b6418daa5fa229ec701fe2",
            "value": 16
          }
        },
        "bf51904065314de48222a4a3c9020c53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aabc039785f742e1bda7102b11ac0a59",
            "placeholder": "​",
            "style": "IPY_MODEL_192ddacd94bb459da666403792a7192b",
            "value": " 16/16 [00:00&lt;00:00, 16.12ba/s]"
          }
        },
        "3557f09c6b81438595837a502bae39f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ad7e3ae59b74c848fb5cee7eea29201": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25f24252c96340f19559727cfb3de776": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9a990af301ed4daaa03937b94f56ca12": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1fc46561e9b6418daa5fa229ec701fe2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "aabc039785f742e1bda7102b11ac0a59": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "192ddacd94bb459da666403792a7192b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d6506b95c0424f308fc8dab31f1c6a72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_999bc93380c14d0086358eaa86bb7131",
              "IPY_MODEL_26d66b4a5d044ce0abd9ab194db3aeac",
              "IPY_MODEL_338c8d8248fd4c5d854137db971cee01"
            ],
            "layout": "IPY_MODEL_bdb88938c8f1469aa76a645822a783ea"
          }
        },
        "999bc93380c14d0086358eaa86bb7131": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_191c9f16792f4259be8948f235a9d594",
            "placeholder": "​",
            "style": "IPY_MODEL_1134dc3850a34d4e951586776ab7fe92",
            "value": "100%"
          }
        },
        "26d66b4a5d044ce0abd9ab194db3aeac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b3945a2d8c34e95b61ee3a332a2e6b6",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7e9a23a0f9aa4d9ba918292b7a2fcffb",
            "value": 1
          }
        },
        "338c8d8248fd4c5d854137db971cee01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7fa78fb01ec94dfdab62f988701cf170",
            "placeholder": "​",
            "style": "IPY_MODEL_8f47f01e5f3744ed860abf4d05e66372",
            "value": " 1/1 [00:00&lt;00:00, 10.39ba/s]"
          }
        },
        "bdb88938c8f1469aa76a645822a783ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "191c9f16792f4259be8948f235a9d594": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1134dc3850a34d4e951586776ab7fe92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6b3945a2d8c34e95b61ee3a332a2e6b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e9a23a0f9aa4d9ba918292b7a2fcffb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7fa78fb01ec94dfdab62f988701cf170": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f47f01e5f3744ed860abf4d05e66372": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b4f5c93141a84d5e988fafd847579de3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1e4be27655be4ec19516fa97d8ff5c0c",
              "IPY_MODEL_a72a252abd9d4df9801d6cc1e057790d",
              "IPY_MODEL_6c150ed4152047139308bdd98db05902"
            ],
            "layout": "IPY_MODEL_73739a4ba97f4885bb885784c48ab879"
          }
        },
        "1e4be27655be4ec19516fa97d8ff5c0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc0d425649a9413cb442e4b3e6c8e4a8",
            "placeholder": "​",
            "style": "IPY_MODEL_94e9719834104d6382977e1dfca85dfd",
            "value": "100%"
          }
        },
        "a72a252abd9d4df9801d6cc1e057790d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ede26ea49694c409982f506687b7127",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_da3f103fbfc9499095efe4210dc6dd6a",
            "value": 1
          }
        },
        "6c150ed4152047139308bdd98db05902": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c88b69aa0e640a793f6ccb0b534b834",
            "placeholder": "​",
            "style": "IPY_MODEL_7113a6b457174bca914916b19c43758e",
            "value": " 1/1 [00:00&lt;00:00, 10.11ba/s]"
          }
        },
        "73739a4ba97f4885bb885784c48ab879": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc0d425649a9413cb442e4b3e6c8e4a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94e9719834104d6382977e1dfca85dfd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3ede26ea49694c409982f506687b7127": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da3f103fbfc9499095efe4210dc6dd6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7c88b69aa0e640a793f6ccb0b534b834": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7113a6b457174bca914916b19c43758e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}